

** [alpha] Launch Training on 20230804_2017
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": true,
  "architecture": "SEGFORMER",
  "baseModel": "MITB4",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 500,
  "resume": false,
  "prevEPOCH": 172,
  "resumeWeight": "./model_weights/ResNet50/20230605_1912_DLV3PP_ResNet50_BEST_AUG/variables/variables",
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 4,
  "early_stop": false,
  "patience": 50,
  "lr_scheduling": "wcos",
  "stepwise_scheduling": true,
  "lr": 0.0001,
  "optimizer": "AdamW",
  "decay_steps": 1.0,
  "warmup": 30,
  "train_annotation": "./Annotations/consolidate_train_db_20230711_1637.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230711_1637.txt",
  "exp_comment": "* Updated Annotations are used\n* Updated consolidate DB used (0711_1637 version) - Updated DB \n* This consolidate DB is updated from 0703_2119 version \n* 4 GPUs are used to train models\n* SEGFORMER Model W/ MIT B2 Pretrained Wegiths\n* Optimize perf: AdamW is used. w/ lr=0.001\n",
  "numGPUs": 4,
  "isCompleted": false,
  "config": "Config/TRAIN_SEGFORMER_NEWDB_20230711_lr.yaml",
  "numTrainDB": 11530,
  "numEvalDB": 3524
}
@20230804_2027 @20230804_2027 [EP 1/500] lr: 3.3333333249174757e-06, took: 598.68s (avg: 598.68s), ETA: 3d:10h:53m:22s [TRAIN] loss: 0.9880, iou: 0.0061, f1: 0.0120 [EVAL] loss: 0.9688, iou: 0.0159, f1: 0.0312
@20230804_2032 @20230804_2032 [EP 2/500] lr: 6.666666649834951e-06, took: 305.94s (avg: 305.94s), ETA: 1d:18h:11m:30s [TRAIN] loss: 0.8757, iou: 0.0687, f1: 0.1243 [EVAL] loss: 0.7802, iou: 0.1259, f1: 0.2198
@20230804_2037 @20230804_2037 [EP 3/500] lr: 9.999999747378752e-06, took: 306.27s (avg: 306.27s), ETA: 1d:18h:14m:42s [TRAIN] loss: 0.7300, iou: 0.1617, f1: 0.2700 [EVAL] loss: 0.6052, iou: 0.2519, f1: 0.3948
@20230804_2043 @20230804_2043 [EP 4/500] lr: 1.3333333299669903e-05, took: 306.44s (avg: 306.44s), ETA: 1d:18h:9m:36s [TRAIN] loss: 0.6077, iou: 0.2531, f1: 0.3923 [EVAL] loss: 0.5732, iou: 0.2815, f1: 0.4268
@20230804_2048 @20230804_2048 [EP 5/500] lr: 1.6666666851961054e-05, took: 302.40s (avg: 302.40s), ETA: 1d:17h:31m:30s [TRAIN] loss: 0.5504, iou: 0.3005, f1: 0.4496 [EVAL] loss: 0.4866, iou: 0.3536, f1: 0.5134
@20230804_2053 @20230804_2053 [EP 6/500] lr: 1.9999999494757503e-05, took: 305.05s (avg: 305.05s), ETA: 1d:17h:51m:10s [TRAIN] loss: 0.4925, iou: 0.3499, f1: 0.5075 [EVAL] loss: 0.4531, iou: 0.3860, f1: 0.5469
@20230804_2058 @20230804_2058 [EP 7/500] lr: 2.3333332137553953e-05, took: 304.55s (avg: 304.55s), ETA: 1d:17h:37m:52s [TRAIN] loss: 0.4575, iou: 0.3827, f1: 0.5425 [EVAL] loss: 0.4280, iou: 0.4099, f1: 0.5720
@20230804_2103 @20230804_2103 [EP 8/500] lr: 2.6666666599339806e-05, took: 301.85s (avg: 301.85s), ETA: 1d:17h:8m:12s [TRAIN] loss: 0.4200, iou: 0.4188, f1: 0.5800 [EVAL] loss: 0.3927, iou: 0.4458, f1: 0.6073
@20230804_2108 @20230804_2108 [EP 9/500] lr: 2.9999999242136255e-05, took: 280.86s (avg: 280.86s), ETA: 1d:14h:11m:20s [TRAIN] loss: 0.3909, iou: 0.4484, f1: 0.6091 [EVAL] loss: 0.3691, iou: 0.4705, f1: 0.6309
@20230804_2113 @20230804_2113 [EP 10/500] lr: 3.333333370392211e-05, took: 293.64s (avg: 293.64s), ETA: 1d:15h:52m:50s [TRAIN] loss: 0.3660, iou: 0.4749, f1: 0.6340 [EVAL] loss: 0.3388, iou: 0.5036, f1: 0.6612
@20230804_2118 @20230804_2118 [EP 11/500] lr: 3.6666664527729154e-05, took: 303.91s (avg: 303.91s), ETA: 1d:17h:9m:27s [TRAIN] loss: 0.3436, iou: 0.4992, f1: 0.6564 [EVAL] loss: 0.3311, iou: 0.5119, f1: 0.6689
@20230804_2123 @20230804_2123 [EP 12/500] lr: 3.9999998989515007e-05, took: 304.11s (avg: 304.11s), ETA: 1d:17h:12m:32s [TRAIN] loss: 0.3252, iou: 0.5202, f1: 0.6748 [EVAL] loss: 0.3197, iou: 0.5255, f1: 0.6803
@20230804_2128 @20230804_2128 [EP 13/500] lr: 4.333333345130086e-05, took: 304.81s (avg: 304.81s), ETA: 1d:17h:7m:28s [TRAIN] loss: 0.3098, iou: 0.5376, f1: 0.6902 [EVAL] loss: 0.3072, iou: 0.5400, f1: 0.6928
@20230804_2133 @20230804_2133 [EP 14/500] lr: 4.6666664275107905e-05, took: 307.49s (avg: 307.49s), ETA: 1d:17h:26m:42s [TRAIN] loss: 0.2986, iou: 0.5508, f1: 0.7014 [EVAL] loss: 0.2972, iou: 0.5510, f1: 0.7028
@20230804_2138 @20230804_2138 [EP 15/500] lr: 4.999999873689376e-05, took: 305.34s (avg: 305.34s), ETA: 1d:17h:5m:25s [TRAIN] loss: 0.2865, iou: 0.5650, f1: 0.7135 [EVAL] loss: 0.2899, iou: 0.5603, f1: 0.7101
@20230804_2144 @20230804_2144 [EP 16/500] lr: 5.333333319867961e-05, took: 305.98s (avg: 305.98s), ETA: 1d:17h:0m:20s [TRAIN] loss: 0.2736, iou: 0.5805, f1: 0.7264 [EVAL] loss: 0.2764, iou: 0.5763, f1: 0.7236
@20230804_2149 @20230804_2149 [EP 17/500] lr: 5.6666667660465464e-05, took: 306.64s (avg: 306.64s), ETA: 1d:17h:3m:18s [TRAIN] loss: 0.2656, iou: 0.5906, f1: 0.7344 [EVAL] loss: 0.2753, iou: 0.5780, f1: 0.7247
@20230804_2154 @20230804_2154 [EP 18/500] lr: 5.999999848427251e-05, took: 305.55s (avg: 305.55s), ETA: 1d:16h:50m:10s [TRAIN] loss: 0.2606, iou: 0.5968, f1: 0.7394 [EVAL] loss: 0.2887, iou: 0.5619, f1: 0.7113
@20230804_2158 @20230804_2158 [EP 19/500] lr: 6.333333294605836e-05, took: 279.44s (avg: 279.44s), ETA: 1d:13h:16m:39s [TRAIN] loss: 0.2503, iou: 0.6097, f1: 0.7497 [EVAL] loss: 0.2699, iou: 0.5848, f1: 0.7301
@20230804_2203 @20230804_2203 [EP 20/500] lr: 6.666666740784422e-05, took: 262.96s (avg: 262.96s), ETA: 1d:10h:56m:0s [TRAIN] loss: 0.2474, iou: 0.6135, f1: 0.7526 [EVAL] loss: 0.2565, iou: 0.6019, f1: 0.7435
@20230804_2207 @20230804_2207 [EP 21/500] lr: 7.000000186963007e-05, took: 263.19s (avg: 263.19s), ETA: 1d:10h:59m:37s [TRAIN] loss: 0.2402, iou: 0.6227, f1: 0.7598 [EVAL] loss: 0.2433, iou: 0.6182, f1: 0.7567
@20230804_2212 @20230804_2212 [EP 22/500] lr: 7.333332905545831e-05, took: 262.39s (avg: 262.39s), ETA: 1d:10h:47m:16s [TRAIN] loss: 0.2441, iou: 0.6195, f1: 0.7559 [EVAL] loss: 0.2723, iou: 0.5825, f1: 0.7277
@20230804_2216 @20230804_2216 [EP 23/500] lr: 7.666666351724416e-05, took: 262.21s (avg: 262.21s), ETA: 1d:10h:42m:54s [TRAIN] loss: 0.2344, iou: 0.6310, f1: 0.7656 [EVAL] loss: 0.2358, iou: 0.6282, f1: 0.7642
@20230804_2221 @20230804_2221 [EP 24/500] lr: 7.999999797903001e-05, took: 262.27s (avg: 262.27s), ETA: 1d:10h:38m:32s [TRAIN] loss: 0.2195, iou: 0.6499, f1: 0.7805 [EVAL] loss: 0.2331, iou: 0.6316, f1: 0.7669
@20230804_2225 @20230804_2225 [EP 25/500] lr: 8.333333244081587e-05, took: 262.58s (avg: 262.58s), ETA: 1d:10h:34m:10s [TRAIN] loss: 0.2157, iou: 0.6550, f1: 0.7843 [EVAL] loss: 0.2331, iou: 0.6321, f1: 0.7669
@20230804_2229 @20230804_2229 [EP 26/500] lr: 8.666666690260172e-05, took: 262.33s (avg: 262.33s), ETA: 1d:10h:29m:48s [TRAIN] loss: 0.2128, iou: 0.6589, f1: 0.7872 [EVAL] loss: 0.2257, iou: 0.6417, f1: 0.7743
@20230804_2238 @20230804_2238 [EP 28/500] lr: 9.333332855021581e-05, took: 263.22s (avg: 263.22s), ETA: 1d:10h:28m:56s [TRAIN] loss: 0.2100, iou: 0.6631, f1: 0.7900 [EVAL] loss: 0.2180, iou: 0.6520, f1: 0.7820
@20230804_2243 @20230804_2243 [EP 29/500] lr: 9.666666301200166e-05, took: 262.44s (avg: 262.44s), ETA: 1d:10h:16m:42s [TRAIN] loss: 0.2176, iou: 0.6535, f1: 0.7824 [EVAL] loss: 0.2449, iou: 0.6195, f1: 0.7551
@20230804_2247 @20230804_2247 [EP 30/500] lr: 9.999999747378752e-05, took: 262.52s (avg: 262.52s), ETA: 1d:10h:12m:20s [TRAIN] loss: 0.2161, iou: 0.6569, f1: 0.7839 [EVAL] loss: 0.2138, iou: 0.6593, f1: 0.7862
@20230804_2252 @20230804_2252 [EP 31/500] lr: 9.999902977142483e-05, took: 262.78s (avg: 262.78s), ETA: 1d:10h:7m:58s [TRAIN] loss: 0.1971, iou: 0.6825, f1: 0.8029 [EVAL] loss: 0.2033, iou: 0.6730, f1: 0.7967
