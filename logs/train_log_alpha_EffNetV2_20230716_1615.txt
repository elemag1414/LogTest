

** [alpha] Launch Training on 20230716_1615
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "architecture": "DLV3+",
  "baseModel": "EffNetV2",
  "numGPUs": 4,
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 500,
  "resume": true,
  "prevEPOCH": 70,
  "resumeWeight": "/home/alpha/WorkSpace/GasDetectionProj/ModelDev/ModelTraining/multi_gpu_logs/model_weights/EffNetV2/20230714_1850_DLV3+_EffNetV2/20230714_1850_DLV3+_EffNetV2_BEST_070/variables/variables",
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 10,
  "lr_scheduling": "cos",
  "lr": 0.01,
  "decay_steps": 1.0,
  "train_annotation": "./Annotations/consolidate_train_db_20230711_1637.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230711_1637.txt",
  "exp_comment": "* Updated Annotations are used\n* Updated consolidate DB used (0711_1637 version) - Updated DB \n* This consolidate DB is updated from 0703_2119 version \n* 4 GPUs are used to train models\n* EffNet Test\n",
  "isCompleted": false,
  "config": "./Config/TRAIN_DLV3_EffNetV2_20230711_resume.yaml",
  "numTrainDB": 11530,
  "numEvalDB": 3524
}
@20230716_1621 @20230716_1621 [EP 71/500] lr: 0.009524134919047356, took: 300.50s (avg: 300.50s), ETA: 1d:11h:45m:0s [TRAIN] loss: 0.1097, iou: 0.8035, f1: 0.8903 [EVAL] loss: 0.1367, iou: 0.7608, f1: 0.8633
@20230716_1624 @20230716_1624 [EP 72/500] lr: 0.009510669857263565, took: 117.72s (avg: 117.72s), ETA: 0d:13h:54m:36s [TRAIN] loss: 0.1069, iou: 0.8081, f1: 0.8931 [EVAL] loss: 0.1335, iou: 0.7658, f1: 0.8665
@20230716_1627 @20230716_1627 [EP 73/500] lr: 0.009497025981545448, took: 112.00s (avg: 112.00s), ETA: 0d:13h:17m:4s [TRAIN] loss: 0.1080, iou: 0.8062, f1: 0.8920 [EVAL] loss: 0.1330, iou: 0.7667, f1: 0.8670
@20230716_1630 @20230716_1630 [EP 74/500] lr: 0.009483205154538155, took: 101.44s (avg: 101.44s), ETA: 0d:11h:57m:6s [TRAIN] loss: 0.1058, iou: 0.8097, f1: 0.8942 [EVAL] loss: 0.1397, iou: 0.7563, f1: 0.8603
@20230716_1632 @20230716_1632 [EP 75/500] lr: 0.009469207376241684, took: 101.05s (avg: 101.05s), ETA: 0d:11h:55m:25s [TRAIN] loss: 0.1086, iou: 0.8055, f1: 0.8914 [EVAL] loss: 0.1372, iou: 0.7602, f1: 0.8628
@20230716_1634 @20230716_1634 [EP 76/500] lr: 0.009455032646656036, took: 101.26s (avg: 101.26s), ETA: 0d:11h:53m:44s [TRAIN] loss: 0.1074, iou: 0.8072, f1: 0.8926 [EVAL] loss: 0.1335, iou: 0.7658, f1: 0.8665
