

** [alpha] Launch Training on 20230822_2100
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": true,
  "architecture": "DLV3+",
  "baseModel": "ResNet50",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 500,
  "resume": false,
  "prevEPOCH": 172,
  "resumeWeight": "./model_weights/ResNet50/20230605_1912_DLV3PP_ResNet50_BEST_AUG/variables/variables",
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 14,
  "optimizer": "Adam",
  "loss": "default",
  "early_stop": true,
  "patience": 30,
  "warmup_epochs": 15,
  "lr_scheduling": "const",
  "lr": 9e-05,
  "stepwise_scheduling": false,
  "decay_steps": 1.0,
  "train_annotation": "./Annotations/consolidate_train_db_20230808_1942.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230808_1942.txt",
  "exp_comment": "* Updated Annotations are used\n* Updated consolidate DB used (20230808_1942 version) - Updated DB \n* 4 GPUs are used to train models\n* It's observed that initLr = 0.008 (stepwise) doesn't show good convergence. \n* So, new experiments on LR have been initiated. \n*   1st (0809_1052):    lr  0.004 : Doesn't seem to work\n*   2nd (0809_1202):    lr  0.001 \n* To improve the accuracy, we perform experiments on loss functions:\n*    We compare: dice loss only vs combined_loss (dice_loss (.7) + focal loss (.3) )\n*                For focal loss alpha of 0.25 and gamma of 2.0, lambda_weight of .3 are used \n*      lr (0810_1613) : 0.001\n*      lr (0810_1711): 0.0008\n*\n*      0811_1027: lambda_weight = .7\n*\n*      0811_16xx: equal loss dice_loss + focal_loss + mse\n",
  "numGPUs": 4,
  "finalEPOCH": 0,
  "isCompleted": false,
  "config": "./Config/TRAIN_DLV3_ResNet50_NEWDB_20230808.yaml",
  "numTrainDB": 11830,
  "numEvalDB": 3600
}
@20230822_2102 @20230822_2102 [EP 1/500] lr: 9.000000136438757e-05, took: 116.44s (avg: 116.44s), ETA: 0d:16h:4m:44s [TRAIN] loss: 0.7248, iou: 0.1761, f1: 0.2752 [EVAL] loss: 0.9950, iou: 0.0025, f1: 0.0050
@20230822_2104 @20230822_2103 [EP 2/500] lr: 9.000000136438757e-05, took: 62.78s (avg: 62.78s), ETA: 0d:8h:34m:36s [TRAIN] loss: 0.2628, iou: 0.5902, f1: 0.7372 [EVAL] loss: 0.9995, iou: 0.0003, f1: 0.0005
@20230822_2105 @20230822_2105 [EP 3/500] lr: 9.000000136438757e-05, took: 61.72s (avg: 61.72s), ETA: 0d:8h:25m:17s [TRAIN] loss: 0.1533, iou: 0.7359, f1: 0.8467 [EVAL] loss: 0.9997, iou: 0.0001, f1: 0.0003
@20230822_2106 @20230822_2106 [EP 4/500] lr: 9.000000136438757e-05, took: 62.22s (avg: 62.22s), ETA: 0d:8h:32m:32s [TRAIN] loss: 0.1182, iou: 0.7894, f1: 0.8818 [EVAL] loss: 0.9885, iou: 0.0061, f1: 0.0115
@20230822_2107 @20230822_2107 [EP 5/500] lr: 9.000000136438757e-05, took: 62.42s (avg: 62.42s), ETA: 0d:8h:31m:30s [TRAIN] loss: 0.1057, iou: 0.8097, f1: 0.8943 [EVAL] loss: 0.7192, iou: 0.1669, f1: 0.2808
@20230822_2108 @20230822_2108 [EP 6/500] lr: 9.000000136438757e-05, took: 60.18s (avg: 60.18s), ETA: 0d:8h:14m:0s [TRAIN] loss: 0.0969, iou: 0.8239, f1: 0.9031 [EVAL] loss: 0.2824, iou: 0.5624, f1: 0.7176
@20230822_2110 @20230822_2110 [EP 7/500] lr: 9.000000136438757e-05, took: 58.33s (avg: 58.33s), ETA: 0d:7h:56m:34s [TRAIN] loss: 0.0939, iou: 0.8290, f1: 0.9061 [EVAL] loss: 0.2084, iou: 0.6571, f1: 0.7916
@20230822_2111 @20230822_2111 [EP 8/500] lr: 9.000000136438757e-05, took: 58.10s (avg: 58.10s), ETA: 0d:7h:55m:36s [TRAIN] loss: 0.0870, iou: 0.8405, f1: 0.9130 [EVAL] loss: 0.1556, iou: 0.7322, f1: 0.8444
@20230822_2112 @20230822_2112 [EP 9/500] lr: 9.000000136438757e-05, took: 57.81s (avg: 57.81s), ETA: 0d:7h:46m:27s [TRAIN] loss: 0.0854, iou: 0.8433, f1: 0.9146 [EVAL] loss: 0.1438, iou: 0.7498, f1: 0.8562
@20230822_2113 @20230822_2113 [EP 10/500] lr: 9.000000136438757e-05, took: 62.70s (avg: 62.70s), ETA: 0d:8h:26m:20s [TRAIN] loss: 0.0802, iou: 0.8520, f1: 0.9198 [EVAL] loss: 0.1331, iou: 0.7663, f1: 0.8669
@20230822_2115 @20230822_2115 [EP 11/500] lr: 9.000000136438757e-05, took: 62.45s (avg: 62.45s), ETA: 0d:8h:25m:18s [TRAIN] loss: 0.0755, iou: 0.8599, f1: 0.9245 [EVAL] loss: 0.1264, iou: 0.7768, f1: 0.8736
@20230822_2116 @20230822_2116 [EP 12/500] lr: 9.000000136438757e-05, took: 63.48s (avg: 63.48s), ETA: 0d:8h:32m:24s [TRAIN] loss: 0.0727, iou: 0.8647, f1: 0.9273 [EVAL] loss: 0.1444, iou: 0.7493, f1: 0.8556
@20230822_2117 @20230822_2117 [EP 13/500] lr: 9.000000136438757e-05, took: 63.28s (avg: 63.28s), ETA: 0d:8h:31m:21s [TRAIN] loss: 0.0746, iou: 0.8614, f1: 0.9254 [EVAL] loss: 0.1267, iou: 0.7763, f1: 0.8733
@20230822_2118 @20230822_2118 [EP 14/500] lr: 9.000000136438757e-05, took: 63.96s (avg: 63.96s), ETA: 0d:8h:30m:18s [TRAIN] loss: 0.0765, iou: 0.8583, f1: 0.9235 [EVAL] loss: 0.1549, iou: 0.7337, f1: 0.8451
@20230822_2119 @20230822_2119 [EP 15/500] lr: 9.000000136438757e-05, took: 63.20s (avg: 63.20s), ETA: 0d:8h:29m:15s [TRAIN] loss: 0.0775, iou: 0.8567, f1: 0.9225 [EVAL] loss: 0.1837, iou: 0.6919, f1: 0.8163
@20230822_2120 @20230822_2120 [EP 16/500] lr: 9.000000136438757e-05, took: 64.40s (avg: 64.40s), ETA: 0d:8h:36m:16s [TRAIN] loss: 0.0712, iou: 0.8674, f1: 0.9288 [EVAL] loss: 0.1406, iou: 0.7547, f1: 0.8594
@20230822_2122 @20230822_2122 [EP 17/500] lr: 9.000000136438757e-05, took: 64.09s (avg: 64.09s), ETA: 0d:8h:35m:12s [TRAIN] loss: 0.0658, iou: 0.8769, f1: 0.9342 [EVAL] loss: 0.1368, iou: 0.7606, f1: 0.8632
@20230822_2123 @20230822_2123 [EP 18/500] lr: 9.000000136438757e-05, took: 62.67s (avg: 62.67s), ETA: 0d:8h:18m:4s [TRAIN] loss: 0.0621, iou: 0.8833, f1: 0.9379 [EVAL] loss: 0.1097, iou: 0.8032, f1: 0.8903
@20230822_2124 @20230822_2124 [EP 19/500] lr: 9.000000136438757e-05, took: 63.08s (avg: 63.08s), ETA: 0d:8h:25m:3s [TRAIN] loss: 0.0609, iou: 0.8855, f1: 0.9391 [EVAL] loss: 0.1123, iou: 0.7990, f1: 0.8877
@20230822_2125 @20230822_2125 [EP 20/500] lr: 9.000000136438757e-05, took: 63.53s (avg: 63.53s), ETA: 0d:8h:24m:0s [TRAIN] loss: 0.0611, iou: 0.8851, f1: 0.9389 [EVAL] loss: 0.1126, iou: 0.7987, f1: 0.8874
@20230822_2126 @20230822_2126 [EP 21/500] lr: 9.000000136438757e-05, took: 63.56s (avg: 63.56s), ETA: 0d:8h:22m:57s [TRAIN] loss: 0.0636, iou: 0.8806, f1: 0.9364 [EVAL] loss: 0.1138, iou: 0.7968, f1: 0.8862
@20230822_2127 @20230822_2127 [EP 22/500] lr: 9.000000136438757e-05, took: 63.66s (avg: 63.66s), ETA: 0d:8h:21m:54s [TRAIN] loss: 0.0656, iou: 0.8771, f1: 0.9344 [EVAL] loss: 0.1109, iou: 0.8017, f1: 0.8891
@20230822_2128 @20230822_2128 [EP 23/500] lr: 9.000000136438757e-05, took: 63.30s (avg: 63.30s), ETA: 0d:8h:20m:51s [TRAIN] loss: 0.0641, iou: 0.8798, f1: 0.9359 [EVAL] loss: 0.1518, iou: 0.7381, f1: 0.8482
@20230822_2129 @20230822_2129 [EP 24/500] lr: 9.000000136438757e-05, took: 64.24s (avg: 64.24s), ETA: 0d:8h:27m:44s [TRAIN] loss: 0.0635, iou: 0.8809, f1: 0.9365 [EVAL] loss: 0.1580, iou: 0.7288, f1: 0.8420
@20230822_2130 @20230822_2130 [EP 25/500] lr: 9.000000136438757e-05, took: 62.83s (avg: 62.83s), ETA: 0d:8h:10m:50s [TRAIN] loss: 0.0639, iou: 0.8802, f1: 0.9361 [EVAL] loss: 0.1250, iou: 0.7791, f1: 0.8750
@20230822_2131 @20230822_2131 [EP 26/500] lr: 9.000000136438757e-05, took: 63.00s (avg: 63.00s), ETA: 0d:8h:9m:48s [TRAIN] loss: 0.0639, iou: 0.8801, f1: 0.9361 [EVAL] loss: 0.2446, iou: 0.6101, f1: 0.7554
@20230822_2133 @20230822_2133 [EP 27/500] lr: 9.000000136438757e-05, took: 63.61s (avg: 63.61s), ETA: 0d:8h:16m:39s [TRAIN] loss: 0.0637, iou: 0.8805, f1: 0.9363 [EVAL] loss: 0.1856, iou: 0.6890, f1: 0.8144
@20230822_2134 @20230822_2134 [EP 28/500] lr: 9.000000136438757e-05, took: 63.09s (avg: 63.09s), ETA: 0d:8h:15m:36s [TRAIN] loss: 0.0622, iou: 0.8831, f1: 0.9378 [EVAL] loss: 0.1469, iou: 0.7452, f1: 0.8531
@20230822_2135 @20230822_2135 [EP 29/500] lr: 4.5000000682193786e-05, took: 63.06s (avg: 63.06s), ETA: 0d:8h:14m:33s [TRAIN] loss: 0.0573, iou: 0.8918, f1: 0.9427 [EVAL] loss: 0.1153, iou: 0.7945, f1: 0.8847
@20230822_2136 @20230822_2136 [EP 30/500] lr: 4.5000000682193786e-05, took: 62.55s (avg: 62.55s), ETA: 0d:8h:5m:40s [TRAIN] loss: 0.0518, iou: 0.9018, f1: 0.9482 [EVAL] loss: 0.1085, iou: 0.8054, f1: 0.8915
@20230822_2137 @20230822_2137 [EP 31/500] lr: 4.5000000682193786e-05, took: 62.83s (avg: 62.83s), ETA: 0d:8h:4m:38s [TRAIN] loss: 0.0493, iou: 0.9063, f1: 0.9507 [EVAL] loss: 0.1166, iou: 0.7925, f1: 0.8834
@20230822_2138 @20230822_2138 [EP 32/500] lr: 4.5000000682193786e-05, took: 62.12s (avg: 62.12s), ETA: 0d:8h:3m:36s [TRAIN] loss: 0.0479, iou: 0.9088, f1: 0.9521 [EVAL] loss: 0.0962, iou: 0.8254, f1: 0.9038
@20230822_2139 @20230822_2139 [EP 33/500] lr: 4.5000000682193786e-05, took: 62.73s (avg: 62.73s), ETA: 0d:8h:2m:34s [TRAIN] loss: 0.0470, iou: 0.9105, f1: 0.9530 [EVAL] loss: 0.1154, iou: 0.7942, f1: 0.8846
@20230822_2141 @20230822_2141 [EP 34/500] lr: 4.5000000682193786e-05, took: 63.74s (avg: 63.74s), ETA: 0d:8h:9m:18s [TRAIN] loss: 0.0464, iou: 0.9115, f1: 0.9536 [EVAL] loss: 0.0986, iou: 0.8214, f1: 0.9014
@20230822_2142 @20230822_2142 [EP 35/500] lr: 4.5000000682193786e-05, took: 63.36s (avg: 63.36s), ETA: 0d:8h:8m:15s [TRAIN] loss: 0.0460, iou: 0.9123, f1: 0.9540 [EVAL] loss: 0.0932, iou: 0.8301, f1: 0.9068
@20230822_2143 @20230822_2143 [EP 36/500] lr: 4.5000000682193786e-05, took: 63.19s (avg: 63.19s), ETA: 0d:8h:7m:12s [TRAIN] loss: 0.0459, iou: 0.9123, f1: 0.9541 [EVAL] loss: 0.1065, iou: 0.8085, f1: 0.8935
@20230822_2144 @20230822_2144 [EP 37/500] lr: 4.5000000682193786e-05, took: 59.26s (avg: 59.26s), ETA: 0d:7h:35m:17s [TRAIN] loss: 0.0464, iou: 0.9114, f1: 0.9536 [EVAL] loss: 0.1280, iou: 0.7743, f1: 0.8720
@20230822_2145 @20230822_2145 [EP 38/500] lr: 4.5000000682193786e-05, took: 58.15s (avg: 58.15s), ETA: 0d:7h:26m:36s [TRAIN] loss: 0.0479, iou: 0.9087, f1: 0.9521 [EVAL] loss: 0.1366, iou: 0.7613, f1: 0.8634
@20230822_2146 @20230822_2146 [EP 39/500] lr: 4.5000000682193786e-05, took: 57.89s (avg: 57.89s), ETA: 0d:7h:17m:57s [TRAIN] loss: 0.0491, iou: 0.9067, f1: 0.9509 [EVAL] loss: 0.1316, iou: 0.7690, f1: 0.8684
@20230822_2147 @20230822_2147 [EP 40/500] lr: 4.5000000682193786e-05, took: 57.84s (avg: 57.84s), ETA: 0d:7h:17m:0s [TRAIN] loss: 0.0490, iou: 0.9068, f1: 0.9510 [EVAL] loss: 0.1216, iou: 0.7846, f1: 0.8784
@20230822_2148 @20230822_2148 [EP 41/500] lr: 4.5000000682193786e-05, took: 57.96s (avg: 57.96s), ETA: 0d:7h:16m:3s [TRAIN] loss: 0.0495, iou: 0.9058, f1: 0.9505 [EVAL] loss: 0.0965, iou: 0.8250, f1: 0.9035
@20230822_2149 @20230822_2149 [EP 42/500] lr: 4.5000000682193786e-05, took: 57.83s (avg: 57.83s), ETA: 0d:7h:15m:6s [TRAIN] loss: 0.0498, iou: 0.9052, f1: 0.9502 [EVAL] loss: 0.0918, iou: 0.8327, f1: 0.9082
@20230822_2150 @20230822_2150 [EP 43/500] lr: 4.5000000682193786e-05, took: 57.88s (avg: 57.88s), ETA: 0d:7h:14m:9s [TRAIN] loss: 0.0486, iou: 0.9075, f1: 0.9514 [EVAL] loss: 0.1111, iou: 0.8012, f1: 0.8889
@20230822_2151 @20230822_2151 [EP 44/500] lr: 4.5000000682193786e-05, took: 57.95s (avg: 57.95s), ETA: 0d:7h:13m:12s [TRAIN] loss: 0.0472, iou: 0.9100, f1: 0.9528 [EVAL] loss: 0.1107, iou: 0.8018, f1: 0.8893
@20230822_2152 @20230822_2152 [EP 45/500] lr: 4.5000000682193786e-05, took: 58.27s (avg: 58.27s), ETA: 0d:7h:19m:50s [TRAIN] loss: 0.0466, iou: 0.9112, f1: 0.9534 [EVAL] loss: 0.0935, iou: 0.8299, f1: 0.9065
@20230822_2153 @20230822_2153 [EP 46/500] lr: 4.5000000682193786e-05, took: 57.90s (avg: 57.90s), ETA: 0d:7h:11m:18s [TRAIN] loss: 0.0471, iou: 0.9102, f1: 0.9529 [EVAL] loss: 0.1058, iou: 0.8099, f1: 0.8942
@20230822_2154 @20230822_2154 [EP 47/500] lr: 4.5000000682193786e-05, took: 57.90s (avg: 57.90s), ETA: 0d:7h:10m:21s [TRAIN] loss: 0.0474, iou: 0.9097, f1: 0.9526 [EVAL] loss: 0.1102, iou: 0.8026, f1: 0.8898
@20230822_2155 @20230822_2155 [EP 48/500] lr: 4.5000000682193786e-05, took: 57.94s (avg: 57.94s), ETA: 0d:7h:9m:24s [TRAIN] loss: 0.0477, iou: 0.9091, f1: 0.9523 [EVAL] loss: 0.1252, iou: 0.7788, f1: 0.8748
@20230822_2156 @20230822_2156 [EP 49/500] lr: 4.5000000682193786e-05, took: 57.91s (avg: 57.91s), ETA: 0d:7h:8m:27s [TRAIN] loss: 0.0483, iou: 0.9080, f1: 0.9517 [EVAL] loss: 0.1043, iou: 0.8122, f1: 0.8957
@20230822_2157 @20230822_2157 [EP 50/500] lr: 4.5000000682193786e-05, took: 58.09s (avg: 58.09s), ETA: 0d:7h:15m:0s [TRAIN] loss: 0.0484, iou: 0.9078, f1: 0.9516 [EVAL] loss: 0.1170, iou: 0.7918, f1: 0.8830
@20230822_2158 @20230822_2158 [EP 51/500] lr: 4.5000000682193786e-05, took: 57.81s (avg: 57.81s), ETA: 0d:7h:6m:33s [TRAIN] loss: 0.0484, iou: 0.9079, f1: 0.9516 [EVAL] loss: 0.1453, iou: 0.7479, f1: 0.8547
