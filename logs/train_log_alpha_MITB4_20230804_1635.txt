

** [alpha] Launch Training on 20230804_1635
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": true,
  "architecture": "SEGFORMER",
  "baseModel": "MITB4",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 500,
  "resume": false,
  "prevEPOCH": 172,
  "resumeWeight": "./model_weights/ResNet50/20230605_1912_DLV3PP_ResNet50_BEST_AUG/variables/variables",
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 4,
  "early_stop": false,
  "patience": 50,
  "lr_scheduling": "wcos",
  "stepwise_scheduling": true,
  "lr": 0.0012,
  "optimizer": "AdamW",
  "decay_steps": 1.0,
  "warmup": 30,
  "train_annotation": "./Annotations/consolidate_train_db_20230711_1637.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230711_1637.txt",
  "exp_comment": "* Updated Annotations are used\n* Updated consolidate DB used (0711_1637 version) - Updated DB \n* This consolidate DB is updated from 0703_2119 version \n* 4 GPUs are used to train models\n* SEGFORMER Model W/ MIT B2 Pretrained Wegiths\n* Optimize perf: AdamW is used. w/ lr=0.001\n",
  "numGPUs": 4,
  "isCompleted": false,
  "config": "Config/TRAIN_SEGFORMER_NEWDB_20230711_lr.yaml",
  "numTrainDB": 11530,
  "numEvalDB": 3524
}
@20230804_1645 @20230804_1645 [EP 1/500] lr: 3.9999998989515007e-05, took: 594.81s (avg: 594.81s), ETA: 3d:10h:20m:6s [TRAIN] loss: 0.8553, iou: 0.0851, f1: 0.1447 [EVAL] loss: 0.8313, iou: 0.0941, f1: 0.1687
@20230804_1650 @20230804_1650 [EP 2/500] lr: 7.999999797903001e-05, took: 306.30s (avg: 306.30s), ETA: 1d:18h:19m:48s [TRAIN] loss: 0.5996, iou: 0.2610, f1: 0.4004 [EVAL] loss: 0.5239, iou: 0.3225, f1: 0.4761
@20230804_1655 @20230804_1655 [EP 3/500] lr: 0.00012000000424450263, took: 304.04s (avg: 304.04s), ETA: 1d:17h:58m:8s [TRAIN] loss: 0.5049, iou: 0.3410, f1: 0.4951 [EVAL] loss: 0.4706, iou: 0.3721, f1: 0.5294
@20230804_1700 @20230804_1700 [EP 4/500] lr: 0.00015999999595806003, took: 304.24s (avg: 304.24s), ETA: 1d:17h:53m:4s [TRAIN] loss: 0.4514, iou: 0.3911, f1: 0.5486 [EVAL] loss: 0.4309, iou: 0.4105, f1: 0.5691
@20230804_1705 @20230804_1705 [EP 5/500] lr: 0.00020000000949949026, took: 273.26s (avg: 273.26s), ETA: 1d:13h:32m:15s [TRAIN] loss: 0.4007, iou: 0.4423, f1: 0.5993 [EVAL] loss: 0.3988, iou: 0.4432, f1: 0.6012
@20230804_1709 @20230804_1709 [EP 6/500] lr: 0.00024000000848900527, took: 262.87s (avg: 262.87s), ETA: 1d:11h:57m:8s [TRAIN] loss: 0.3615, iou: 0.4841, f1: 0.6385 [EVAL] loss: 0.3506, iou: 0.4948, f1: 0.6494
@20230804_1713 @20230804_1713 [EP 7/500] lr: 0.0002800000074785203, took: 263.10s (avg: 263.10s), ETA: 1d:12h:0m:59s [TRAIN] loss: 0.3427, iou: 0.5052, f1: 0.6574 [EVAL] loss: 0.3573, iou: 0.4876, f1: 0.6427
@20230804_1718 @20230804_1718 [EP 8/500] lr: 0.00031999999191612005, took: 262.55s (avg: 262.55s), ETA: 1d:11h:48m:24s [TRAIN] loss: 0.3253, iou: 0.5254, f1: 0.6747 [EVAL] loss: 0.3218, iou: 0.5262, f1: 0.6782
@20230804_1723 @20230804_1723 [EP 9/500] lr: 0.0003600000054575503, took: 288.93s (avg: 288.93s), ETA: 1d:15h:16m:48s [TRAIN] loss: 0.3110, iou: 0.5422, f1: 0.6890 [EVAL] loss: 0.3313, iou: 0.5163, f1: 0.6687
@20230804_1728 @20230804_1728 [EP 10/500] lr: 0.0004000000189989805, took: 305.93s (avg: 305.93s), ETA: 1d:17h:30m:50s [TRAIN] loss: 0.2957, iou: 0.5610, f1: 0.7043 [EVAL] loss: 0.2914, iou: 0.5625, f1: 0.7086
@20230804_1733 @20230804_1733 [EP 11/500] lr: 0.0004400000034365803, took: 304.03s (avg: 304.03s), ETA: 1d:17h:17m:36s [TRAIN] loss: 0.3151, iou: 0.5413, f1: 0.6849 [EVAL] loss: 0.3368, iou: 0.5101, f1: 0.6632
@20230804_1738 @20230804_1738 [EP 12/500] lr: 0.00048000001697801054, took: 304.32s (avg: 304.32s), ETA: 1d:17h:12m:32s [TRAIN] loss: 0.2905, iou: 0.5676, f1: 0.7095 [EVAL] loss: 0.2672, iou: 0.5927, f1: 0.7328
@20230804_1743 @20230804_1743 [EP 13/500] lr: 0.0005200000014156103, took: 303.03s (avg: 303.03s), ETA: 1d:16h:59m:21s [TRAIN] loss: 0.2550, iou: 0.6101, f1: 0.7450 [EVAL] loss: 0.2620, iou: 0.5983, f1: 0.7380
@20230804_1748 @20230804_1748 [EP 14/500] lr: 0.0005600000149570405, took: 304.32s (avg: 304.32s), ETA: 1d:17h:2m:24s [TRAIN] loss: 0.2568, iou: 0.6077, f1: 0.7432 [EVAL] loss: 0.2963, iou: 0.5554, f1: 0.7037
@20230804_1753 @20230804_1753 [EP 15/500] lr: 0.0006000000284984708, took: 304.29s (avg: 304.29s), ETA: 1d:16h:57m:20s [TRAIN] loss: 0.3276, iou: 0.5290, f1: 0.6724 [EVAL] loss: 0.3047, iou: 0.5489, f1: 0.6953
@20230804_1758 @20230804_1758 [EP 16/500] lr: 0.0006399999838322401, took: 303.05s (avg: 303.05s), ETA: 1d:16h:44m:12s [TRAIN] loss: 0.2968, iou: 0.5607, f1: 0.7032 [EVAL] loss: 0.2760, iou: 0.5839, f1: 0.7240
@20230804_1803 @20230804_1803 [EP 17/500] lr: 0.0006799999973736703, took: 282.86s (avg: 282.86s), ETA: 1d:13h:50m:6s [TRAIN] loss: 0.2626, iou: 0.6028, f1: 0.7374 [EVAL] loss: 0.2747, iou: 0.5851, f1: 0.7253
@20230804_1808 @20230804_1808 [EP 18/500] lr: 0.0007200000109151006, took: 262.07s (avg: 262.07s), ETA: 1d:11h:4m:44s [TRAIN] loss: 0.2584, iou: 0.6087, f1: 0.7416 [EVAL] loss: 0.2814, iou: 0.5776, f1: 0.7186
@20230804_1812 @20230804_1812 [EP 19/500] lr: 0.0007600000244565308, took: 261.98s (avg: 261.98s), ETA: 1d:10h:52m:21s [TRAIN] loss: 0.2655, iou: 0.5989, f1: 0.7345 [EVAL] loss: 0.2667, iou: 0.5931, f1: 0.7333
@20230804_1816 @20230804_1816 [EP 20/500] lr: 0.000800000037997961, took: 262.30s (avg: 262.30s), ETA: 1d:10h:56m:0s [TRAIN] loss: 0.3028, iou: 0.5571, f1: 0.6972 [EVAL] loss: 0.3772, iou: 0.4685, f1: 0.6228
@20230804_1821 @20230804_1821 [EP 21/500] lr: 0.0008399999933317304, took: 261.71s (avg: 261.71s), ETA: 1d:10h:43m:39s [TRAIN] loss: 0.2763, iou: 0.5861, f1: 0.7237 [EVAL] loss: 0.2465, iou: 0.6196, f1: 0.7535
@20230804_1825 @20230804_1825 [EP 22/500] lr: 0.0008800000068731606, took: 262.29s (avg: 262.29s), ETA: 1d:10h:47m:16s [TRAIN] loss: 0.2377, iou: 0.6336, f1: 0.7623 [EVAL] loss: 0.2553, iou: 0.6070, f1: 0.7447
@20230804_1830 @20230804_1830 [EP 23/500] lr: 0.0009200000204145908, took: 262.19s (avg: 262.19s), ETA: 1d:10h:42m:54s [TRAIN] loss: 0.2792, iou: 0.5877, f1: 0.7208 [EVAL] loss: 0.6167, iou: 0.2528, f1: 0.3833
@20230804_1834 @20230804_1834 [EP 24/500] lr: 0.0009600000339560211, took: 262.18s (avg: 262.18s), ETA: 1d:10h:38m:32s [TRAIN] loss: 0.4644, iou: 0.3916, f1: 0.5356 [EVAL] loss: 0.3384, iou: 0.5139, f1: 0.6616
