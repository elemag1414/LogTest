

** [alpha] Launch Training on 20230801_2014
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": true,
  "architecture": "DLV3+",
  "baseModel": "ResNet50",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 300,
  "resume": false,
  "prevEPOCH": 172,
  "resumeWeight": "./model_weights/ResNet50/20230605_1912_DLV3PP_ResNet50_BEST_AUG/variables/variables",
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 14,
  "early_stop": false,
  "patience": 50,
  "lr_scheduling": "exp",
  "warmup": 50,
  "lr": 0.008,
  "decay_steps": 1.0,
  "train_annotation": "./Annotations/consolidate_train_db_20230711_1637.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230711_1637.txt",
  "exp_comment": "* Updated Annotations are used\n* Updated consolidate DB used (0711_1637 version) - Updated DB \n* This consolidate DB is updated from 0703_2119 version \n* 4 GPUs are used to train models\n",
  "numGPUs": 4,
  "finalEPOCH": 0,
  "isCompleted": false,
  "config": "Config/TRAIN_DLV3_ResNet50_NEWDB_20230711_exp.yaml",
  "numTrainDB": 11530,
  "numEvalDB": 3524
}
@20230801_2017 @20230801_2017 [EP 1/300] lr: 0.008, took: 120.30s (avg: 120.30s), ETA: 0d:9h:58m:0s [TRAIN] loss: 0.4025, iou: 0.4600, f1: 0.5975 [EVAL] loss: 1.0000, iou: 0.0000, f1: 0.0000
@20230801_2018 @20230801_2018 [EP 2/300] lr: 0.008, took: 68.05s (avg: 68.05s), ETA: 0d:5h:37m:44s [TRAIN] loss: 0.2064, iou: 0.6625, f1: 0.7936 [EVAL] loss: 0.9621, iou: 0.0214, f1: 0.0379
@20230801_2019 @20230801_2019 [EP 3/300] lr: 0.008, took: 68.98s (avg: 68.98s), ETA: 0d:5h:36m:36s [TRAIN] loss: 0.1607, iou: 0.7254, f1: 0.8393 [EVAL] loss: 0.9283, iou: 0.0428, f1: 0.0717
@20230801_2021 @20230801_2021 [EP 4/300] lr: 0.008, took: 67.73s (avg: 67.73s), ETA: 0d:5h:30m:32s [TRAIN] loss: 0.1423, iou: 0.7525, f1: 0.8577 [EVAL] loss: 0.7912, iou: 0.1212, f1: 0.2088
@20230801_2022 @20230801_2022 [EP 5/300] lr: 0.008, took: 68.07s (avg: 68.07s), ETA: 0d:5h:34m:20s [TRAIN] loss: 0.1252, iou: 0.7787, f1: 0.8748 [EVAL] loss: 0.2127, iou: 0.6522, f1: 0.7873
@20230801_2023 @20230801_2023 [EP 6/300] lr: 0.008, took: 68.43s (avg: 68.43s), ETA: 0d:5h:33m:12s [TRAIN] loss: 0.1141, iou: 0.7962, f1: 0.8859 [EVAL] loss: 0.4644, iou: 0.3730, f1: 0.5356
@20230801_2025 @20230801_2025 [EP 7/300] lr: 0.008, took: 68.44s (avg: 68.44s), ETA: 0d:5h:32m:4s [TRAIN] loss: 0.1080, iou: 0.8060, f1: 0.8920 [EVAL] loss: 0.1872, iou: 0.6882, f1: 0.8128
@20230801_2026 @20230801_2026 [EP 8/300] lr: 0.008, took: 67.56s (avg: 67.56s), ETA: 0d:5h:26m:4s [TRAIN] loss: 0.1023, iou: 0.8152, f1: 0.8977 [EVAL] loss: 0.2244, iou: 0.6374, f1: 0.7756
@20230801_2027 @20230801_2027 [EP 9/300] lr: 0.008, took: 68.07s (avg: 68.07s), ETA: 0d:5h:29m:48s [TRAIN] loss: 0.0947, iou: 0.8277, f1: 0.9053 [EVAL] loss: 0.9828, iou: 0.0087, f1: 0.0172
@20230801_2028 @20230801_2028 [EP 10/300] lr: 0.008, took: 66.72s (avg: 66.72s), ETA: 0d:5h:19m:0s [TRAIN] loss: 0.0942, iou: 0.8286, f1: 0.9058 [EVAL] loss: 0.7122, iou: 0.1734, f1: 0.2878
