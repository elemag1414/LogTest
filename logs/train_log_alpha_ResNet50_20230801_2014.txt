

** [alpha] Launch Training on 20230801_2014
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": true,
  "architecture": "DLV3+",
  "baseModel": "ResNet50",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 300,
  "resume": false,
  "prevEPOCH": 172,
  "resumeWeight": "./model_weights/ResNet50/20230605_1912_DLV3PP_ResNet50_BEST_AUG/variables/variables",
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 14,
  "early_stop": false,
  "patience": 50,
  "lr_scheduling": "exp",
  "warmup": 50,
  "lr": 0.008,
  "decay_steps": 1.0,
  "train_annotation": "./Annotations/consolidate_train_db_20230711_1637.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230711_1637.txt",
  "exp_comment": "* Updated Annotations are used\n* Updated consolidate DB used (0711_1637 version) - Updated DB \n* This consolidate DB is updated from 0703_2119 version \n* 4 GPUs are used to train models\n",
  "numGPUs": 4,
  "finalEPOCH": 0,
  "isCompleted": false,
  "config": "Config/TRAIN_DLV3_ResNet50_NEWDB_20230711_exp.yaml",
  "numTrainDB": 11530,
  "numEvalDB": 3524
}
@20230801_2017 @20230801_2017 [EP 1/300] lr: 0.008, took: 120.30s (avg: 120.30s), ETA: 0d:9h:58m:0s [TRAIN] loss: 0.4025, iou: 0.4600, f1: 0.5975 [EVAL] loss: 1.0000, iou: 0.0000, f1: 0.0000
@20230801_2018 @20230801_2018 [EP 2/300] lr: 0.008, took: 68.05s (avg: 68.05s), ETA: 0d:5h:37m:44s [TRAIN] loss: 0.2064, iou: 0.6625, f1: 0.7936 [EVAL] loss: 0.9621, iou: 0.0214, f1: 0.0379
@20230801_2019 @20230801_2019 [EP 3/300] lr: 0.008, took: 68.98s (avg: 68.98s), ETA: 0d:5h:36m:36s [TRAIN] loss: 0.1607, iou: 0.7254, f1: 0.8393 [EVAL] loss: 0.9283, iou: 0.0428, f1: 0.0717
@20230801_2021 @20230801_2021 [EP 4/300] lr: 0.008, took: 67.73s (avg: 67.73s), ETA: 0d:5h:30m:32s [TRAIN] loss: 0.1423, iou: 0.7525, f1: 0.8577 [EVAL] loss: 0.7912, iou: 0.1212, f1: 0.2088
@20230801_2022 @20230801_2022 [EP 5/300] lr: 0.008, took: 68.07s (avg: 68.07s), ETA: 0d:5h:34m:20s [TRAIN] loss: 0.1252, iou: 0.7787, f1: 0.8748 [EVAL] loss: 0.2127, iou: 0.6522, f1: 0.7873
@20230801_2023 @20230801_2023 [EP 6/300] lr: 0.008, took: 68.43s (avg: 68.43s), ETA: 0d:5h:33m:12s [TRAIN] loss: 0.1141, iou: 0.7962, f1: 0.8859 [EVAL] loss: 0.4644, iou: 0.3730, f1: 0.5356
@20230801_2025 @20230801_2025 [EP 7/300] lr: 0.008, took: 68.44s (avg: 68.44s), ETA: 0d:5h:32m:4s [TRAIN] loss: 0.1080, iou: 0.8060, f1: 0.8920 [EVAL] loss: 0.1872, iou: 0.6882, f1: 0.8128
@20230801_2026 @20230801_2026 [EP 8/300] lr: 0.008, took: 67.56s (avg: 67.56s), ETA: 0d:5h:26m:4s [TRAIN] loss: 0.1023, iou: 0.8152, f1: 0.8977 [EVAL] loss: 0.2244, iou: 0.6374, f1: 0.7756
@20230801_2027 @20230801_2027 [EP 9/300] lr: 0.008, took: 68.07s (avg: 68.07s), ETA: 0d:5h:29m:48s [TRAIN] loss: 0.0947, iou: 0.8277, f1: 0.9053 [EVAL] loss: 0.9828, iou: 0.0087, f1: 0.0172
@20230801_2028 @20230801_2028 [EP 10/300] lr: 0.008, took: 66.72s (avg: 66.72s), ETA: 0d:5h:19m:0s [TRAIN] loss: 0.0942, iou: 0.8286, f1: 0.9058 [EVAL] loss: 0.7122, iou: 0.1734, f1: 0.2878
@20230801_2029 @20230801_2029 [EP 11/300] lr: 0.008, took: 67.27s (avg: 67.27s), ETA: 0d:5h:22m:43s [TRAIN] loss: 0.0904, iou: 0.8349, f1: 0.9096 [EVAL] loss: 0.3489, iou: 0.4885, f1: 0.6511
@20230801_2031 @20230801_2031 [EP 12/300] lr: 0.008, took: 69.76s (avg: 69.76s), ETA: 0d:5h:31m:12s [TRAIN] loss: 0.0878, iou: 0.8393, f1: 0.9122 [EVAL] loss: 0.7978, iou: 0.1162, f1: 0.2022
@20230801_2032 @20230801_2032 [EP 13/300] lr: 0.008, took: 67.75s (avg: 67.75s), ETA: 0d:5h:20m:29s [TRAIN] loss: 0.0814, iou: 0.8500, f1: 0.9186 [EVAL] loss: 0.4496, iou: 0.3880, f1: 0.5504
@20230801_2033 @20230801_2033 [EP 14/300] lr: 0.008, took: 67.99s (avg: 67.99s), ETA: 0d:5h:19m:22s [TRAIN] loss: 0.0827, iou: 0.8480, f1: 0.9173 [EVAL] loss: 0.8702, iou: 0.0727, f1: 0.1298
@20230801_2034 @20230801_2034 [EP 15/300] lr: 0.008, took: 67.00s (avg: 67.00s), ETA: 0d:5h:13m:30s [TRAIN] loss: 0.0801, iou: 0.8523, f1: 0.9199 [EVAL] loss: 0.6336, iou: 0.2321, f1: 0.3664
@20230801_2035 @20230801_2035 [EP 16/300] lr: 0.008, took: 67.62s (avg: 67.62s), ETA: 0d:5h:17m:8s [TRAIN] loss: 0.0804, iou: 0.8517, f1: 0.9196 [EVAL] loss: 0.3771, iou: 0.4584, f1: 0.6229
@20230801_2036 @20230801_2036 [EP 17/300] lr: 0.008, took: 68.09s (avg: 68.09s), ETA: 0d:5h:20m:44s [TRAIN] loss: 0.0846, iou: 0.8446, f1: 0.9154 [EVAL] loss: 0.8731, iou: 0.0711, f1: 0.1269
@20230801_2037 @20230801_2037 [EP 18/300] lr: 0.008, took: 67.26s (avg: 67.26s), ETA: 0d:5h:14m:54s [TRAIN] loss: 0.0786, iou: 0.8547, f1: 0.9214 [EVAL] loss: 0.2889, iou: 0.5566, f1: 0.7111
@20230801_2039 @20230801_2039 [EP 19/300] lr: 0.008, took: 67.91s (avg: 67.91s), ETA: 0d:5h:13m:47s [TRAIN] loss: 0.0775, iou: 0.8567, f1: 0.9225 [EVAL] loss: 0.9828, iou: 0.0111, f1: 0.0172
@20230801_2040 @20230801_2040 [EP 20/300] lr: 0.008, took: 68.15s (avg: 68.15s), ETA: 0d:5h:17m:20s [TRAIN] loss: 0.0708, iou: 0.8682, f1: 0.9292 [EVAL] loss: 0.9721, iou: 0.0179, f1: 0.0279
@20230801_2041 @20230801_2041 [EP 21/300] lr: 0.008, took: 67.56s (avg: 67.56s), ETA: 0d:5h:11m:33s [TRAIN] loss: 0.0718, iou: 0.8666, f1: 0.9282 [EVAL] loss: 0.8757, iou: 0.0713, f1: 0.1243
@20230801_2042 @20230801_2042 [EP 22/300] lr: 0.008, took: 67.93s (avg: 67.93s), ETA: 0d:5h:10m:26s [TRAIN] loss: 0.0691, iou: 0.8711, f1: 0.9309 [EVAL] loss: 0.9803, iou: 0.0101, f1: 0.0197
@20230801_2043 @20230801_2043 [EP 23/300] lr: 0.008, took: 68.06s (avg: 68.06s), ETA: 0d:5h:13m:56s [TRAIN] loss: 0.0679, iou: 0.8732, f1: 0.9321 [EVAL] loss: 0.9891, iou: 0.0058, f1: 0.0109
