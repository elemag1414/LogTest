

** [alpha] Launch Training on 20230820_1214
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": true,
  "architecture": "DLV3+",
  "baseModel": "ResNet50",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 500,
  "resume": false,
  "prevEPOCH": 172,
  "resumeWeight": "./model_weights/ResNet50/20230605_1912_DLV3PP_ResNet50_BEST_AUG/variables/variables",
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 14,
  "optimizer": "Adam",
  "loss": "default",
  "early_stop": false,
  "lr_scheduling": "const",
  "lr": 6e-05,
  "stepwise_scheduling": false,
  "decay_steps": 1.0,
  "train_annotation": "./Annotations/consolidate_train_db_20230808_1942.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230808_1942.txt",
  "exp_comment": "* Updated Annotations are used\n* Updated consolidate DB used (20230808_1942 version) - Updated DB \n* 4 GPUs are used to train models\n* It's observed that initLr = 0.008 (stepwise) doesn't show good convergence. \n* So, new experiments on LR have been initiated. \n*   1st (0809_1052):    lr  0.004 : Doesn't seem to work\n*   2nd (0809_1202):    lr  0.001 \n* To improve the accuracy, we perform experiments on loss functions:\n*    We compare: dice loss only vs combined_loss (dice_loss (.7) + focal loss (.3) )\n*                For focal loss alpha of 0.25 and gamma of 2.0, lambda_weight of .3 are used \n*      lr (0810_1613) : 0.001\n*      lr (0810_1711): 0.0008\n*\n*      0811_1027: lambda_weight = .7\n*\n*      0811_16xx: equal loss dice_loss + focal_loss + mse\n",
  "numGPUs": 4,
  "finalEPOCH": 0,
  "isCompleted": false,
  "config": "./Config/TRAIN_DLV3_ResNet50_NEWDB_20230808.yaml",
  "numTrainDB": 11830,
  "numEvalDB": 3600
}
@20230820_1216 @20230820_1216 [EP 1/500] lr: 5.999999848427251e-05, took: 114.81s (avg: 114.81s), ETA: 0d:15h:48m:6s [TRAIN] loss: 0.8864, iou: 0.0630, f1: 0.1136 [EVAL] loss: 0.9946, iou: 0.0027, f1: 0.0054
@20230820_1217 @20230820_1217 [EP 2/500] lr: 5.999999848427251e-05, took: 63.00s (avg: 63.00s), ETA: 0d:8h:42m:54s [TRAIN] loss: 0.5285, iou: 0.3204, f1: 0.4715 [EVAL] loss: 0.9975, iou: 0.0012, f1: 0.0025
@20230820_1218 @20230820_1218 [EP 3/500] lr: 5.999999848427251e-05, took: 62.94s (avg: 62.94s), ETA: 0d:8h:33m:34s [TRAIN] loss: 0.2666, iou: 0.5844, f1: 0.7334 [EVAL] loss: 0.9992, iou: 0.0004, f1: 0.0008
@20230820_1219 @20230820_1219 [EP 4/500] lr: 5.999999848427251e-05, took: 63.17s (avg: 63.17s), ETA: 0d:8h:40m:48s [TRAIN] loss: 0.1706, iou: 0.7106, f1: 0.8294 [EVAL] loss: 0.9964, iou: 0.0019, f1: 0.0036
@20230820_1220 @20230820_1220 [EP 5/500] lr: 5.999999848427251e-05, took: 58.36s (avg: 58.36s), ETA: 0d:7h:58m:30s [TRAIN] loss: 0.1355, iou: 0.7626, f1: 0.8645 [EVAL] loss: 0.7128, iou: 0.1729, f1: 0.2872
@20230820_1221 @20230820_1221 [EP 6/500] lr: 5.999999848427251e-05, took: 58.14s (avg: 58.14s), ETA: 0d:7h:57m:32s [TRAIN] loss: 0.1179, iou: 0.7901, f1: 0.8821 [EVAL] loss: 0.2959, iou: 0.5459, f1: 0.7041
@20230820_1222 @20230820_1222 [EP 7/500] lr: 5.999999848427251e-05, took: 58.09s (avg: 58.09s), ETA: 0d:7h:56m:34s [TRAIN] loss: 0.1059, iou: 0.8094, f1: 0.8941 [EVAL] loss: 0.2171, iou: 0.6450, f1: 0.7829
@20230820_1223 @20230820_1223 [EP 8/500] lr: 5.999999848427251e-05, took: 58.40s (avg: 58.40s), ETA: 0d:7h:55m:36s [TRAIN] loss: 0.0996, iou: 0.8196, f1: 0.9004 [EVAL] loss: 0.1717, iou: 0.7085, f1: 0.8283
@20230820_1224 @20230820_1224 [EP 9/500] lr: 5.999999848427251e-05, took: 58.37s (avg: 58.37s), ETA: 0d:7h:54m:38s [TRAIN] loss: 0.0903, iou: 0.8349, f1: 0.9097 [EVAL] loss: 0.1900, iou: 0.6829, f1: 0.8100
@20230820_1225 @20230820_1225 [EP 10/500] lr: 5.999999848427251e-05, took: 58.07s (avg: 58.07s), ETA: 0d:7h:53m:40s [TRAIN] loss: 0.0842, iou: 0.8452, f1: 0.9158 [EVAL] loss: 0.2006, iou: 0.6681, f1: 0.7994
@20230820_1226 @20230820_1226 [EP 11/500] lr: 5.999999848427251e-05, took: 58.09s (avg: 58.09s), ETA: 0d:7h:52m:42s [TRAIN] loss: 0.0869, iou: 0.8406, f1: 0.9131 [EVAL] loss: 0.2880, iou: 0.5569, f1: 0.7120
@20230820_1227 @20230820_1227 [EP 12/500] lr: 5.999999848427251e-05, took: 58.10s (avg: 58.10s), ETA: 0d:7h:51m:44s [TRAIN] loss: 0.0840, iou: 0.8455, f1: 0.9160 [EVAL] loss: 0.1833, iou: 0.6920, f1: 0.8167
@20230820_1228 @20230820_1228 [EP 13/500] lr: 5.999999848427251e-05, took: 58.34s (avg: 58.34s), ETA: 0d:7h:50m:46s [TRAIN] loss: 0.0773, iou: 0.8568, f1: 0.9227 [EVAL] loss: 0.1509, iou: 0.7394, f1: 0.8491
@20230820_1229 @20230820_1229 [EP 14/500] lr: 5.999999848427251e-05, took: 58.38s (avg: 58.38s), ETA: 0d:7h:49m:48s [TRAIN] loss: 0.0728, iou: 0.8646, f1: 0.9272 [EVAL] loss: 0.1394, iou: 0.7567, f1: 0.8606
@20230820_1230 @20230820_1230 [EP 15/500] lr: 5.999999848427251e-05, took: 58.77s (avg: 58.77s), ETA: 0d:7h:48m:50s [TRAIN] loss: 0.0704, iou: 0.8688, f1: 0.9296 [EVAL] loss: 0.1641, iou: 0.7202, f1: 0.8359
@20230820_1231 @20230820_1231 [EP 16/500] lr: 5.999999848427251e-05, took: 57.98s (avg: 57.98s), ETA: 0d:7h:39m:48s [TRAIN] loss: 0.0711, iou: 0.8675, f1: 0.9289 [EVAL] loss: 0.2435, iou: 0.6117, f1: 0.7565
@20230820_1232 @20230820_1232 [EP 17/500] lr: 5.999999848427251e-05, took: 58.15s (avg: 58.15s), ETA: 0d:7h:46m:54s [TRAIN] loss: 0.0727, iou: 0.8648, f1: 0.9273 [EVAL] loss: 0.1767, iou: 0.7018, f1: 0.8233
@20230820_1233 @20230820_1233 [EP 18/500] lr: 5.999999848427251e-05, took: 59.90s (avg: 59.90s), ETA: 0d:7h:53m:58s [TRAIN] loss: 0.0730, iou: 0.8643, f1: 0.9270 [EVAL] loss: 0.2275, iou: 0.6324, f1: 0.7725
@20230820_1234 @20230820_1234 [EP 19/500] lr: 5.999999848427251e-05, took: 63.19s (avg: 63.19s), ETA: 0d:8h:25m:3s [TRAIN] loss: 0.0712, iou: 0.8675, f1: 0.9288 [EVAL] loss: 0.1619, iou: 0.7227, f1: 0.8381
@20230820_1235 @20230820_1235 [EP 20/500] lr: 5.999999848427251e-05, took: 63.78s (avg: 63.78s), ETA: 0d:8h:24m:0s [TRAIN] loss: 0.0669, iou: 0.8749, f1: 0.9331 [EVAL] loss: 0.1589, iou: 0.7274, f1: 0.8411
@20230820_1236 @20230820_1236 [EP 21/500] lr: 5.999999848427251e-05, took: 62.82s (avg: 62.82s), ETA: 0d:8h:14m:58s [TRAIN] loss: 0.0648, iou: 0.8785, f1: 0.9352 [EVAL] loss: 0.1175, iou: 0.7905, f1: 0.8825
@20230820_1237 @20230820_1237 [EP 22/500] lr: 5.999999848427251e-05, took: 65.11s (avg: 65.11s), ETA: 0d:8h:37m:50s [TRAIN] loss: 0.0646, iou: 0.8789, f1: 0.9354 [EVAL] loss: 0.1151, iou: 0.7944, f1: 0.8849
@20230820_1238 @20230820_1238 [EP 23/500] lr: 5.999999848427251e-05, took: 64.92s (avg: 64.92s), ETA: 0d:8h:28m:48s [TRAIN] loss: 0.0673, iou: 0.8743, f1: 0.9327 [EVAL] loss: 0.1071, iou: 0.8072, f1: 0.8929
@20230820_1239 @20230820_1239 [EP 24/500] lr: 5.999999848427251e-05, took: 63.04s (avg: 63.04s), ETA: 0d:8h:19m:48s [TRAIN] loss: 0.0661, iou: 0.8764, f1: 0.9339 [EVAL] loss: 0.1563, iou: 0.7314, f1: 0.8437
@20230820_1240 @20230820_1240 [EP 25/500] lr: 5.999999848427251e-05, took: 63.15s (avg: 63.15s), ETA: 0d:8h:18m:45s [TRAIN] loss: 0.0642, iou: 0.8795, f1: 0.9358 [EVAL] loss: 0.1337, iou: 0.7652, f1: 0.8663
@20230820_1241 @20230820_1241 [EP 26/500] lr: 5.999999848427251e-05, took: 62.80s (avg: 62.80s), ETA: 0d:8h:9m:48s [TRAIN] loss: 0.0606, iou: 0.8860, f1: 0.9394 [EVAL] loss: 0.1359, iou: 0.7618, f1: 0.8641
@20230820_1243 @20230820_1243 [EP 27/500] lr: 5.999999848427251e-05, took: 62.91s (avg: 62.91s), ETA: 0d:8h:8m:46s [TRAIN] loss: 0.0589, iou: 0.8889, f1: 0.9411 [EVAL] loss: 0.1438, iou: 0.7499, f1: 0.8562
@20230820_1244 @20230820_1244 [EP 28/500] lr: 5.999999848427251e-05, took: 63.71s (avg: 63.71s), ETA: 0d:8h:15m:36s [TRAIN] loss: 0.0583, iou: 0.8901, f1: 0.9417 [EVAL] loss: 0.1220, iou: 0.7836, f1: 0.8780
@20230820_1245 @20230820_1245 [EP 29/500] lr: 5.999999848427251e-05, took: 63.08s (avg: 63.08s), ETA: 0d:8h:14m:33s [TRAIN] loss: 0.0593, iou: 0.8883, f1: 0.9407 [EVAL] loss: 0.1043, iou: 0.8121, f1: 0.8957
@20230820_1246 @20230820_1246 [EP 30/500] lr: 5.999999848427251e-05, took: 62.62s (avg: 62.62s), ETA: 0d:8h:5m:40s [TRAIN] loss: 0.0602, iou: 0.8867, f1: 0.9398 [EVAL] loss: 0.1191, iou: 0.7884, f1: 0.8809
@20230820_1247 @20230820_1247 [EP 31/500] lr: 5.999999848427251e-05, took: 64.22s (avg: 64.22s), ETA: 0d:8h:20m:16s [TRAIN] loss: 0.0604, iou: 0.8864, f1: 0.9396 [EVAL] loss: 0.2051, iou: 0.6624, f1: 0.7949
@20230820_1248 @20230820_1248 [EP 32/500] lr: 5.999999848427251e-05, took: 63.28s (avg: 63.28s), ETA: 0d:8h:11m:24s [TRAIN] loss: 0.0607, iou: 0.8859, f1: 0.9393 [EVAL] loss: 0.1096, iou: 0.8035, f1: 0.8904
@20230820_1249 @20230820_1249 [EP 33/500] lr: 5.999999848427251e-05, took: 63.61s (avg: 63.61s), ETA: 0d:8h:10m:21s [TRAIN] loss: 0.0612, iou: 0.8849, f1: 0.9388 [EVAL] loss: 0.0953, iou: 0.8267, f1: 0.9047
@20230820_1250 @20230820_1250 [EP 34/500] lr: 5.999999848427251e-05, took: 63.73s (avg: 63.73s), ETA: 0d:8h:9m:18s [TRAIN] loss: 0.0603, iou: 0.8866, f1: 0.9397 [EVAL] loss: 0.1026, iou: 0.8148, f1: 0.8974
@20230820_1251 @20230820_1251 [EP 35/500] lr: 5.999999848427251e-05, took: 62.96s (avg: 62.96s), ETA: 0d:8h:0m:30s [TRAIN] loss: 0.0604, iou: 0.8864, f1: 0.9396 [EVAL] loss: 0.1490, iou: 0.7424, f1: 0.8510
@20230820_1252 @20230820_1252 [EP 36/500] lr: 5.999999848427251e-05, took: 63.25s (avg: 63.25s), ETA: 0d:8h:7m:12s [TRAIN] loss: 0.0612, iou: 0.8849, f1: 0.9388 [EVAL] loss: 0.1819, iou: 0.6948, f1: 0.8181
@20230820_1253 @20230820_1253 [EP 37/500] lr: 5.999999848427251e-05, took: 63.40s (avg: 63.40s), ETA: 0d:8h:6m:9s [TRAIN] loss: 0.0590, iou: 0.8889, f1: 0.9410 [EVAL] loss: 0.1354, iou: 0.7633, f1: 0.8646
@20230820_1254 @20230820_1254 [EP 38/500] lr: 5.999999848427251e-05, took: 63.18s (avg: 63.18s), ETA: 0d:8h:5m:6s [TRAIN] loss: 0.0546, iou: 0.8966, f1: 0.9454 [EVAL] loss: 0.1016, iou: 0.8164, f1: 0.8984
@20230820_1256 @20230820_1256 [EP 39/500] lr: 5.999999848427251e-05, took: 63.61s (avg: 63.61s), ETA: 0d:8h:4m:3s [TRAIN] loss: 0.0521, iou: 0.9011, f1: 0.9479 [EVAL] loss: 0.0941, iou: 0.8288, f1: 0.9059
@20230820_1257 @20230820_1257 [EP 40/500] lr: 5.999999848427251e-05, took: 62.63s (avg: 62.63s), ETA: 0d:7h:55m:20s [TRAIN] loss: 0.0517, iou: 0.9018, f1: 0.9483 [EVAL] loss: 0.1185, iou: 0.7892, f1: 0.8815
@20230820_1258 @20230820_1258 [EP 41/500] lr: 5.999999848427251e-05, took: 62.99s (avg: 62.99s), ETA: 0d:7h:54m:18s [TRAIN] loss: 0.0522, iou: 0.9010, f1: 0.9478 [EVAL] loss: 0.1427, iou: 0.7516, f1: 0.8573
