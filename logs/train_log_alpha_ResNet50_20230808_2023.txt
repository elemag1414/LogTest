

** [alpha] Launch Training on 20230808_2023
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": true,
  "architecture": "DLV3+",
  "baseModel": "ResNet50",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 500,
  "resume": false,
  "prevEPOCH": 172,
  "resumeWeight": "./model_weights/ResNet50/20230605_1912_DLV3PP_ResNet50_BEST_AUG/variables/variables",
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 14,
  "optimizer": "Adam",
  "early_stop": false,
  "lr_scheduling": "exp",
  "lr": 0.008,
  "stepwise_scheduling": true,
  "decay_steps": 1.0,
  "train_annotation": "./Annotations/consolidate_train_db_20230808_1942.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230808_1942.txt",
  "exp_comment": "* Updated Annotations are used\n* Updated consolidate DB used (20230808_1942 version) - Updated DB \n* 4 GPUs are used to train models\n",
  "numGPUs": 4,
  "finalEPOCH": 0,
  "isCompleted": false,
  "config": "Config/TRAIN_DLV3_ResNet50_NEWDB_20230808.yaml",
  "numTrainDB": 11830,
  "numEvalDB": 3600
}
@20230808_2025 @20230808_2025 [EP 1/500] lr: 0.006849315483123064, took: 129.17s (avg: 129.17s), ETA: 0d:17h:52m:51s [TRAIN] loss: 0.4112, iou: 0.4513, f1: 0.5888 [EVAL] loss: 1.0000, iou: 0.0000, f1: 0.0000
@20230808_2026 @20230808_2026 [EP 2/500] lr: 0.005984440911561251, took: 70.46s (avg: 70.46s), ETA: 0d:9h:41m:0s [TRAIN] loss: 0.2112, iou: 0.6556, f1: 0.7888 [EVAL] loss: 1.0000, iou: 0.0000, f1: 0.0000
@20230808_2028 @20230808_2028 [EP 3/500] lr: 0.005313496571034193, took: 69.47s (avg: 69.47s), ETA: 0d:9h:31m:33s [TRAIN] loss: 0.1665, iou: 0.7174, f1: 0.8335 [EVAL] loss: 0.9831, iou: 0.0090, f1: 0.0169
@20230808_2029 @20230808_2029 [EP 4/500] lr: 0.004777831025421619, took: 69.77s (avg: 69.77s), ETA: 0d:9h:30m:24s [TRAIN] loss: 0.1449, iou: 0.7494, f1: 0.8551 [EVAL] loss: 0.9097, iou: 0.0503, f1: 0.0903
@20230808_2030 @20230808_2030 [EP 5/500] lr: 0.00434027798473835, took: 69.85s (avg: 69.85s), ETA: 0d:9h:29m:15s [TRAIN] loss: 0.1330, iou: 0.7677, f1: 0.8670 [EVAL] loss: 0.3908, iou: 0.4434, f1: 0.6092
@20230808_2032 @20230808_2032 [EP 6/500] lr: 0.003976142965257168, took: 69.12s (avg: 69.12s), ETA: 0d:9h:28m:6s [TRAIN] loss: 0.1225, iou: 0.7841, f1: 0.8775 [EVAL] loss: 0.2441, iou: 0.6115, f1: 0.7559
@20230808_2033 @20230808_2033 [EP 7/500] lr: 0.0036683788057416677, took: 69.13s (avg: 69.13s), ETA: 0d:9h:26m:57s [TRAIN] loss: 0.1154, iou: 0.7953, f1: 0.8846 [EVAL] loss: 0.6010, iou: 0.2559, f1: 0.3990
@20230808_2034 @20230808_2034 [EP 8/500] lr: 0.003404835006222129, took: 68.88s (avg: 68.88s), ETA: 0d:9h:17m:36s [TRAIN] loss: 0.1111, iou: 0.8023, f1: 0.8889 [EVAL] loss: 0.3935, iou: 0.4407, f1: 0.6065
@20230808_2036 @20230808_2036 [EP 9/500] lr: 0.0031766199972480536, took: 70.65s (avg: 70.65s), ETA: 0d:9h:32m:50s [TRAIN] loss: 0.1061, iou: 0.8104, f1: 0.8939 [EVAL] loss: 0.1935, iou: 0.6787, f1: 0.8065
@20230808_2037 @20230808_2037 [EP 10/500] lr: 0.0029770766850560904, took: 60.14s (avg: 60.14s), ETA: 0d:8h:10m:0s [TRAIN] loss: 0.1055, iou: 0.8114, f1: 0.8945 [EVAL] loss: 0.1624, iou: 0.7227, f1: 0.8376
@20230808_2038 @20230808_2038 [EP 11/500] lr: 0.0028011207468807697, took: 58.74s (avg: 58.74s), ETA: 0d:7h:52m:42s [TRAIN] loss: 0.1015, iou: 0.8179, f1: 0.8985 [EVAL] loss: 0.2384, iou: 0.6199, f1: 0.7616
@20230808_2039 @20230808_2039 [EP 12/500] lr: 0.0026448031421750784, took: 65.30s (avg: 65.30s), ETA: 0d:8h:48m:40s [TRAIN] loss: 0.0977, iou: 0.8242, f1: 0.9023 [EVAL] loss: 0.1903, iou: 0.6840, f1: 0.8097
@20230808_2040 @20230808_2040 [EP 13/500] lr: 0.0025050099939107895, took: 69.10s (avg: 69.10s), ETA: 0d:9h:20m:3s [TRAIN] loss: 0.0927, iou: 0.8324, f1: 0.9073 [EVAL] loss: 0.4141, iou: 0.4202, f1: 0.5859
@20230808_2042 @20230808_2042 [EP 14/500] lr: 0.002379253040999174, took: 69.09s (avg: 69.09s), ETA: 0d:9h:18m:54s [TRAIN] loss: 0.0899, iou: 0.8371, f1: 0.9101 [EVAL] loss: 0.1189, iou: 0.7894, f1: 0.8811
@20230808_2043 @20230808_2043 [EP 15/500] lr: 0.0022655187640339136, took: 69.61s (avg: 69.61s), ETA: 0d:9h:17m:45s [TRAIN] loss: 0.0876, iou: 0.8409, f1: 0.9124 [EVAL] loss: 0.1386, iou: 0.7587, f1: 0.8614
@20230808_2044 @20230808_2044 [EP 16/500] lr: 0.0021621622145175934, took: 69.36s (avg: 69.36s), ETA: 0d:9h:16m:36s [TRAIN] loss: 0.0867, iou: 0.8426, f1: 0.9133 [EVAL] loss: 0.9533, iou: 0.0256, f1: 0.0467
@20230808_2045 @20230808_2045 [EP 17/500] lr: 0.0020678245928138494, took: 70.12s (avg: 70.12s), ETA: 0d:9h:23m:30s [TRAIN] loss: 0.0849, iou: 0.8456, f1: 0.9151 [EVAL] loss: 0.1383, iou: 0.7594, f1: 0.8617
@20230808_2047 @20230808_2047 [EP 18/500] lr: 0.001981375040486455, took: 70.24s (avg: 70.24s), ETA: 0d:9h:22m:20s [TRAIN] loss: 0.0847, iou: 0.8459, f1: 0.9153 [EVAL] loss: 0.2990, iou: 0.5460, f1: 0.7010
@20230808_2048 @20230808_2048 [EP 19/500] lr: 0.0019018639577552676, took: 69.44s (avg: 69.44s), ETA: 0d:9h:13m:9s [TRAIN] loss: 0.0852, iou: 0.8451, f1: 0.9148 [EVAL] loss: 0.0992, iou: 0.8219, f1: 0.9008
@20230808_2049 @20230808_2049 [EP 20/500] lr: 0.001828487846069038, took: 70.10s (avg: 70.10s), ETA: 0d:9h:20m:0s [TRAIN] loss: 0.0852, iou: 0.8450, f1: 0.9148 [EVAL] loss: 0.1692, iou: 0.7141, f1: 0.8308
@20230808_2050 @20230808_2050 [EP 21/500] lr: 0.0017605634639039636, took: 69.38s (avg: 69.38s), ETA: 0d:9h:10m:51s [TRAIN] loss: 0.0844, iou: 0.8465, f1: 0.9156 [EVAL] loss: 0.2066, iou: 0.6613, f1: 0.7934
@20230808_2052 @20230808_2052 [EP 22/500] lr: 0.0016975047765299678, took: 69.85s (avg: 69.85s), ETA: 0d:9h:9m:42s [TRAIN] loss: 0.0816, iou: 0.8512, f1: 0.9184 [EVAL] loss: 0.1047, iou: 0.8128, f1: 0.8953
@20230808_2053 @20230808_2053 [EP 23/500] lr: 0.0016388068906962872, took: 70.04s (avg: 70.04s), ETA: 0d:9h:16m:30s [TRAIN] loss: 0.0781, iou: 0.8571, f1: 0.9219 [EVAL] loss: 0.1092, iou: 0.8050, f1: 0.8908
@20230808_2054 @20230808_2054 [EP 24/500] lr: 0.0015840328997001052, took: 70.73s (avg: 70.73s), ETA: 0d:9h:15m:20s [TRAIN] loss: 0.0770, iou: 0.8590, f1: 0.9230 [EVAL] loss: 0.1428, iou: 0.7530, f1: 0.8572
