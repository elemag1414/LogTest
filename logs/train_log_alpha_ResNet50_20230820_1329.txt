

** [alpha] Launch Training on 20230820_1329
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": true,
  "architecture": "DLV3+",
  "baseModel": "ResNet50",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 500,
  "resume": false,
  "prevEPOCH": 172,
  "resumeWeight": "./model_weights/ResNet50/20230605_1912_DLV3PP_ResNet50_BEST_AUG/variables/variables",
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 14,
  "optimizer": "Adam",
  "loss": "default",
  "early_stop": false,
  "lr_scheduling": "const",
  "lr": 2e-05,
  "stepwise_scheduling": false,
  "decay_steps": 1.0,
  "train_annotation": "./Annotations/consolidate_train_db_20230808_1942.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230808_1942.txt",
  "exp_comment": "* Updated Annotations are used\n* Updated consolidate DB used (20230808_1942 version) - Updated DB \n* 4 GPUs are used to train models\n* It's observed that initLr = 0.008 (stepwise) doesn't show good convergence. \n* So, new experiments on LR have been initiated. \n*   1st (0809_1052):    lr  0.004 : Doesn't seem to work\n*   2nd (0809_1202):    lr  0.001 \n* To improve the accuracy, we perform experiments on loss functions:\n*    We compare: dice loss only vs combined_loss (dice_loss (.7) + focal loss (.3) )\n*                For focal loss alpha of 0.25 and gamma of 2.0, lambda_weight of .3 are used \n*      lr (0810_1613) : 0.001\n*      lr (0810_1711): 0.0008\n*\n*      0811_1027: lambda_weight = .7\n*\n*      0811_16xx: equal loss dice_loss + focal_loss + mse\n",
  "numGPUs": 4,
  "finalEPOCH": 0,
  "isCompleted": false,
  "config": "./Config/TRAIN_DLV3_ResNet50_NEWDB_20230808.yaml",
  "numTrainDB": 11830,
  "numEvalDB": 3600
}
@20230820_1331 @20230820_1331 [EP 1/500] lr: 1.9999999494757503e-05, took: 114.98s (avg: 114.98s), ETA: 0d:15h:48m:6s [TRAIN] loss: 0.9444, iou: 0.0293, f1: 0.0556 [EVAL] loss: 0.9951, iou: 0.0025, f1: 0.0049
@20230820_1332 @20230820_1332 [EP 2/500] lr: 1.9999999494757503e-05, took: 63.09s (avg: 63.09s), ETA: 0d:8h:42m:54s [TRAIN] loss: 0.8244, iou: 0.0989, f1: 0.1756 [EVAL] loss: 0.9949, iou: 0.0026, f1: 0.0051
@20230820_1333 @20230820_1333 [EP 3/500] lr: 1.9999999494757503e-05, took: 62.46s (avg: 62.46s), ETA: 0d:8h:33m:34s [TRAIN] loss: 0.6865, iou: 0.1911, f1: 0.3135 [EVAL] loss: 0.9958, iou: 0.0021, f1: 0.0042
@20230820_1334 @20230820_1334 [EP 4/500] lr: 1.9999999494757503e-05, took: 62.92s (avg: 62.92s), ETA: 0d:8h:32m:32s [TRAIN] loss: 0.5376, iou: 0.3075, f1: 0.4624 [EVAL] loss: 0.9916, iou: 0.0043, f1: 0.0084
@20230820_1335 @20230820_1335 [EP 5/500] lr: 1.9999999494757503e-05, took: 62.81s (avg: 62.81s), ETA: 0d:8h:31m:30s [TRAIN] loss: 0.4118, iou: 0.4230, f1: 0.5882 [EVAL] loss: 0.7764, iou: 0.1287, f1: 0.2236
@20230820_1336 @20230820_1336 [EP 6/500] lr: 1.9999999494757503e-05, took: 63.51s (avg: 63.51s), ETA: 0d:8h:38m:42s [TRAIN] loss: 0.3209, iou: 0.5192, f1: 0.6791 [EVAL] loss: 0.4916, iou: 0.3440, f1: 0.5084
@20230820_1337 @20230820_1337 [EP 7/500] lr: 1.9999999494757503e-05, took: 63.18s (avg: 63.18s), ETA: 0d:8h:37m:39s [TRAIN] loss: 0.2586, iou: 0.5931, f1: 0.7414 [EVAL] loss: 0.4573, iou: 0.3756, f1: 0.5427
@20230820_1338 @20230820_1338 [EP 8/500] lr: 1.9999999494757503e-05, took: 62.98s (avg: 62.98s), ETA: 0d:8h:28m:24s [TRAIN] loss: 0.2145, iou: 0.6498, f1: 0.7855 [EVAL] loss: 0.5467, iou: 0.2968, f1: 0.4533
@20230820_1340 @20230820_1340 [EP 9/500] lr: 1.9999999494757503e-05, took: 64.23s (avg: 64.23s), ETA: 0d:8h:43m:44s [TRAIN] loss: 0.1823, iou: 0.6938, f1: 0.8177 [EVAL] loss: 0.2581, iou: 0.5932, f1: 0.7419
@20230820_1341 @20230820_1341 [EP 10/500] lr: 1.9999999494757503e-05, took: 62.76s (avg: 62.76s), ETA: 0d:8h:26m:20s [TRAIN] loss: 0.1634, iou: 0.7211, f1: 0.8366 [EVAL] loss: 0.2487, iou: 0.6066, f1: 0.7513
@20230820_1342 @20230820_1342 [EP 11/500] lr: 1.9999999494757503e-05, took: 57.95s (avg: 57.95s), ETA: 0d:7h:44m:33s [TRAIN] loss: 0.1415, iou: 0.7535, f1: 0.8585 [EVAL] loss: 0.2181, iou: 0.6484, f1: 0.7819
@20230820_1343 @20230820_1343 [EP 12/500] lr: 1.9999999494757503e-05, took: 57.95s (avg: 57.95s), ETA: 0d:7h:43m:36s [TRAIN] loss: 0.1263, iou: 0.7768, f1: 0.8737 [EVAL] loss: 0.2071, iou: 0.6625, f1: 0.7929
@20230820_1344 @20230820_1344 [EP 13/500] lr: 1.9999999494757503e-05, took: 57.95s (avg: 57.95s), ETA: 0d:7h:42m:39s [TRAIN] loss: 0.1156, iou: 0.7937, f1: 0.8844 [EVAL] loss: 0.2298, iou: 0.6330, f1: 0.7702
@20230820_1345 @20230820_1345 [EP 14/500] lr: 1.9999999494757503e-05, took: 57.95s (avg: 57.95s), ETA: 0d:7h:41m:42s [TRAIN] loss: 0.1071, iou: 0.8073, f1: 0.8929 [EVAL] loss: 0.2262, iou: 0.6373, f1: 0.7738
@20230820_1346 @20230820_1346 [EP 15/500] lr: 1.9999999494757503e-05, took: 58.31s (avg: 58.31s), ETA: 0d:7h:48m:50s [TRAIN] loss: 0.1014, iou: 0.8165, f1: 0.8986 [EVAL] loss: 0.2552, iou: 0.6002, f1: 0.7448
@20230820_1347 @20230820_1347 [EP 16/500] lr: 1.9999999494757503e-05, took: 62.74s (avg: 62.74s), ETA: 0d:8h:20m:8s [TRAIN] loss: 0.0990, iou: 0.8206, f1: 0.9010 [EVAL] loss: 0.1816, iou: 0.6977, f1: 0.8184
@20230820_1348 @20230820_1348 [EP 17/500] lr: 1.9999999494757503e-05, took: 63.25s (avg: 63.25s), ETA: 0d:8h:27m:9s [TRAIN] loss: 0.0986, iou: 0.8213, f1: 0.9014 [EVAL] loss: 0.2148, iou: 0.6528, f1: 0.7852
@20230820_1349 @20230820_1349 [EP 18/500] lr: 1.9999999494757503e-05, took: 63.52s (avg: 63.52s), ETA: 0d:8h:26m:6s [TRAIN] loss: 0.0973, iou: 0.8233, f1: 0.9027 [EVAL] loss: 0.2247, iou: 0.6381, f1: 0.7753
@20230820_1350 @20230820_1350 [EP 19/500] lr: 1.9999999494757503e-05, took: 62.54s (avg: 62.54s), ETA: 0d:8h:17m:2s [TRAIN] loss: 0.0928, iou: 0.8308, f1: 0.9072 [EVAL] loss: 0.2093, iou: 0.6584, f1: 0.7907
@20230820_1351 @20230820_1351 [EP 20/500] lr: 1.9999999494757503e-05, took: 63.56s (avg: 63.56s), ETA: 0d:8h:24m:0s [TRAIN] loss: 0.0843, iou: 0.8450, f1: 0.9157 [EVAL] loss: 0.2228, iou: 0.6407, f1: 0.7772
@20230820_1352 @20230820_1352 [EP 21/500] lr: 1.9999999494757503e-05, took: 62.65s (avg: 62.65s), ETA: 0d:8h:14m:58s [TRAIN] loss: 0.0802, iou: 0.8519, f1: 0.9198 [EVAL] loss: 0.2179, iou: 0.6480, f1: 0.7821
@20230820_1353 @20230820_1353 [EP 22/500] lr: 1.9999999494757503e-05, took: 62.95s (avg: 62.95s), ETA: 0d:8h:13m:56s [TRAIN] loss: 0.0777, iou: 0.8561, f1: 0.9223 [EVAL] loss: 0.2209, iou: 0.6457, f1: 0.7791
@20230820_1354 @20230820_1354 [EP 23/500] lr: 1.9999999494757503e-05, took: 62.72s (avg: 62.72s), ETA: 0d:8h:12m:54s [TRAIN] loss: 0.0756, iou: 0.8598, f1: 0.9244 [EVAL] loss: 0.2463, iou: 0.6117, f1: 0.7537
@20230820_1355 @20230820_1355 [EP 24/500] lr: 1.9999999494757503e-05, took: 63.05s (avg: 63.05s), ETA: 0d:8h:19m:48s [TRAIN] loss: 0.0745, iou: 0.8617, f1: 0.9255 [EVAL] loss: 0.2653, iou: 0.5881, f1: 0.7347
@20230820_1356 @20230820_1356 [EP 25/500] lr: 1.9999999494757503e-05, took: 62.85s (avg: 62.85s), ETA: 0d:8h:10m:50s [TRAIN] loss: 0.0775, iou: 0.8566, f1: 0.9225 [EVAL] loss: 0.2032, iou: 0.6694, f1: 0.7968
@20230820_1357 @20230820_1357 [EP 26/500] lr: 1.9999999494757503e-05, took: 64.09s (avg: 64.09s), ETA: 0d:8h:25m:36s [TRAIN] loss: 0.0792, iou: 0.8537, f1: 0.9208 [EVAL] loss: 0.1782, iou: 0.7055, f1: 0.8218
@20230820_1359 @20230820_1359 [EP 27/500] lr: 1.9999999494757503e-05, took: 63.20s (avg: 63.20s), ETA: 0d:8h:16m:39s [TRAIN] loss: 0.0801, iou: 0.8522, f1: 0.9199 [EVAL] loss: 0.2590, iou: 0.5963, f1: 0.7410
@20230820_1400 @20230820_1400 [EP 28/500] lr: 1.9999999494757503e-05, took: 63.45s (avg: 63.45s), ETA: 0d:8h:15m:36s [TRAIN] loss: 0.0781, iou: 0.8556, f1: 0.9219 [EVAL] loss: 0.1659, iou: 0.7229, f1: 0.8341
@20230820_1401 @20230820_1401 [EP 29/500] lr: 1.9999999494757503e-05, took: 63.27s (avg: 63.27s), ETA: 0d:8h:14m:33s [TRAIN] loss: 0.0731, iou: 0.8642, f1: 0.9269 [EVAL] loss: 0.2288, iou: 0.6358, f1: 0.7712
@20230820_1402 @20230820_1402 [EP 30/500] lr: 1.9999999494757503e-05, took: 63.86s (avg: 63.86s), ETA: 0d:8h:13m:30s [TRAIN] loss: 0.0706, iou: 0.8684, f1: 0.9294 [EVAL] loss: 0.2294, iou: 0.6345, f1: 0.7706
@20230820_1403 @20230820_1403 [EP 31/500] lr: 1.9999999494757503e-05, took: 63.29s (avg: 63.29s), ETA: 0d:8h:12m:27s [TRAIN] loss: 0.0714, iou: 0.8671, f1: 0.9286 [EVAL] loss: 0.3335, iou: 0.5079, f1: 0.6665
@20230820_1404 @20230820_1404 [EP 32/500] lr: 1.9999999494757503e-05, took: 63.03s (avg: 63.03s), ETA: 0d:8h:11m:24s [TRAIN] loss: 0.0756, iou: 0.8600, f1: 0.9244 [EVAL] loss: 0.2300, iou: 0.6343, f1: 0.7700
@20230820_1405 @20230820_1405 [EP 33/500] lr: 1.9999999494757503e-05, took: 63.13s (avg: 63.13s), ETA: 0d:8h:10m:21s [TRAIN] loss: 0.0737, iou: 0.8632, f1: 0.9263 [EVAL] loss: 0.1600, iou: 0.7324, f1: 0.8400
@20230820_1406 @20230820_1406 [EP 34/500] lr: 1.9999999494757503e-05, took: 63.83s (avg: 63.83s), ETA: 0d:8h:9m:18s [TRAIN] loss: 0.0695, iou: 0.8703, f1: 0.9305 [EVAL] loss: 0.1512, iou: 0.7459, f1: 0.8488
@20230820_1407 @20230820_1407 [EP 35/500] lr: 1.9999999494757503e-05, took: 63.31s (avg: 63.31s), ETA: 0d:8h:8m:15s [TRAIN] loss: 0.0662, iou: 0.8762, f1: 0.9338 [EVAL] loss: 0.1566, iou: 0.7384, f1: 0.8434
@20230820_1408 @20230820_1408 [EP 36/500] lr: 1.9999999494757503e-05, took: 63.08s (avg: 63.08s), ETA: 0d:8h:7m:12s [TRAIN] loss: 0.0637, iou: 0.8805, f1: 0.9363 [EVAL] loss: 0.1496, iou: 0.7483, f1: 0.8504
@20230820_1409 @20230820_1409 [EP 37/500] lr: 1.9999999494757503e-05, took: 63.38s (avg: 63.38s), ETA: 0d:8h:6m:9s [TRAIN] loss: 0.0622, iou: 0.8832, f1: 0.9378 [EVAL] loss: 0.1401, iou: 0.7638, f1: 0.8599
@20230820_1410 @20230820_1410 [EP 38/500] lr: 1.9999999494757503e-05, took: 64.08s (avg: 64.08s), ETA: 0d:8h:12m:48s [TRAIN] loss: 0.0612, iou: 0.8850, f1: 0.9388 [EVAL] loss: 0.1572, iou: 0.7365, f1: 0.8428
@20230820_1412 @20230820_1412 [EP 39/500] lr: 1.9999999494757503e-05, took: 63.85s (avg: 63.85s), ETA: 0d:8h:4m:3s [TRAIN] loss: 0.0604, iou: 0.8864, f1: 0.9396 [EVAL] loss: 0.1563, iou: 0.7384, f1: 0.8437
@20230820_1413 @20230820_1413 [EP 40/500] lr: 1.9999999494757503e-05, took: 62.90s (avg: 62.90s), ETA: 0d:7h:55m:20s [TRAIN] loss: 0.0599, iou: 0.8872, f1: 0.9401 [EVAL] loss: 0.1488, iou: 0.7504, f1: 0.8512
@20230820_1414 @20230820_1414 [EP 41/500] lr: 1.9999999494757503e-05, took: 63.32s (avg: 63.32s), ETA: 0d:8h:1m:57s [TRAIN] loss: 0.0602, iou: 0.8867, f1: 0.9398 [EVAL] loss: 0.1676, iou: 0.7207, f1: 0.8324
@20230820_1415 @20230820_1415 [EP 42/500] lr: 1.9999999494757503e-05, took: 62.96s (avg: 62.96s), ETA: 0d:7h:53m:16s [TRAIN] loss: 0.0604, iou: 0.8863, f1: 0.9396 [EVAL] loss: 0.1546, iou: 0.7397, f1: 0.8454
@20230820_1416 @20230820_1416 [EP 43/500] lr: 1.9999999494757503e-05, took: 63.31s (avg: 63.31s), ETA: 0d:7h:59m:51s [TRAIN] loss: 0.0618, iou: 0.8838, f1: 0.9382 [EVAL] loss: 0.1390, iou: 0.7638, f1: 0.8610
@20230820_1417 @20230820_1417 [EP 44/500] lr: 1.9999999494757503e-05, took: 63.23s (avg: 63.23s), ETA: 0d:7h:58m:48s [TRAIN] loss: 0.0653, iou: 0.8777, f1: 0.9347 [EVAL] loss: 0.1553, iou: 0.7369, f1: 0.8447
@20230820_1418 @20230820_1418 [EP 45/500] lr: 1.9999999494757503e-05, took: 63.54s (avg: 63.54s), ETA: 0d:7h:57m:45s [TRAIN] loss: 0.0660, iou: 0.8764, f1: 0.9340 [EVAL] loss: 0.1780, iou: 0.7060, f1: 0.8220
@20230820_1419 @20230820_1419 [EP 46/500] lr: 1.9999999494757503e-05, took: 63.41s (avg: 63.41s), ETA: 0d:7h:56m:42s [TRAIN] loss: 0.0659, iou: 0.8767, f1: 0.9341 [EVAL] loss: 0.1723, iou: 0.7129, f1: 0.8277
@20230820_1420 @20230820_1420 [EP 47/500] lr: 1.9999999494757503e-05, took: 63.53s (avg: 63.53s), ETA: 0d:7h:55m:39s [TRAIN] loss: 0.0645, iou: 0.8792, f1: 0.9355 [EVAL] loss: 0.1769, iou: 0.7062, f1: 0.8231
@20230820_1421 @20230820_1421 [EP 48/500] lr: 1.9999999494757503e-05, took: 62.81s (avg: 62.81s), ETA: 0d:7h:47m:4s [TRAIN] loss: 0.0638, iou: 0.8803, f1: 0.9362 [EVAL] loss: 0.2325, iou: 0.6291, f1: 0.7675
