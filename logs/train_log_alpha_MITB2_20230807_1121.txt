

** [alpha] Launch Training on 20230807_1121
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": true,
  "architecture": "SEGFORMER",
  "baseModel": "MITB2",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 500,
  "resume": false,
  "prevEPOCH": 172,
  "resumeWeight": "./model_weights/ResNet50/20230605_1912_DLV3PP_ResNet50_BEST_AUG/variables/variables",
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 10,
  "early_stop": false,
  "patience": 50,
  "lr_scheduling": "wcos",
  "stepwise_scheduling": true,
  "lr": 0.0004,
  "optimizer": "AdamW",
  "decay_steps": 1.0,
  "warmup": 30,
  "train_annotation": "./Annotations/consolidate_train_db_20230711_1637.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230711_1637.txt",
  "exp_comment": "* Updated Annotations are used\n* Updated consolidate DB used (0711_1637 version) - Updated DB \n* This consolidate DB is updated from 0703_2119 version \n* 4 GPUs are used to train models\n* SEGFORMER Model W/ MIT B2 Pretrained Wegiths\n* Optimize perf: AdamW is used. w/ lr=0.001\n",
  "numGPUs": 4,
  "isCompleted": false,
  "config": "Config/TRAIN_SEGFORMER_NEWDB_20230711_lr.yaml",
  "numTrainDB": 11530,
  "numEvalDB": 3524
}
@20230807_1126 @20230807_1126 [EP 1/500] lr: 1.3333332390175201e-05, took: 249.60s (avg: 249.60s), ETA: 1d:10h:30m:51s [TRAIN] loss: 0.9785, iou: 0.0111, f1: 0.0215 [EVAL] loss: 0.9591, iou: 0.0210, f1: 0.0409
@20230807_1128 @20230807_1128 [EP 2/500] lr: 2.6666664780350402e-05, took: 121.83s (avg: 121.83s), ETA: 0d:16h:44m:18s [TRAIN] loss: 0.8888, iou: 0.0601, f1: 0.1112 [EVAL] loss: 0.9197, iou: 0.0421, f1: 0.0803
@20230807_1130 @20230807_1130 [EP 3/500] lr: 3.9999998989515007e-05, took: 118.22s (avg: 118.22s), ETA: 0d:16h:17m:26s [TRAIN] loss: 0.8007, iou: 0.1136, f1: 0.1993 [EVAL] loss: 0.7253, iou: 0.1619, f1: 0.2747
@20230807_1132 @20230807_1132 [EP 4/500] lr: 5.3333329560700804e-05, took: 117.92s (avg: 117.92s), ETA: 0d:16h:7m:12s [TRAIN] loss: 0.6882, iou: 0.1892, f1: 0.3118 [EVAL] loss: 0.6600, iou: 0.2081, f1: 0.3400
@20230807_1134 @20230807_1134 [EP 5/500] lr: 6.66666601318866e-05, took: 121.68s (avg: 121.68s), ETA: 0d:16h:38m:15s [TRAIN] loss: 0.5971, iou: 0.2579, f1: 0.4029 [EVAL] loss: 0.5474, iou: 0.2974, f1: 0.4526
@20230807_1136 @20230807_1136 [EP 6/500] lr: 7.999999797903001e-05, took: 127.28s (avg: 127.28s), ETA: 0d:17h:25m:38s [TRAIN] loss: 0.5200, iou: 0.3219, f1: 0.4800 [EVAL] loss: 0.4681, iou: 0.3673, f1: 0.5319
@20230807_1138 @20230807_1138 [EP 7/500] lr: 9.333332855021581e-05, took: 126.23s (avg: 126.23s), ETA: 0d:17h:15m:18s [TRAIN] loss: 0.4549, iou: 0.3818, f1: 0.5451 [EVAL] loss: 0.4141, iou: 0.4201, f1: 0.5859
@20230807_1140 @20230807_1140 [EP 8/500] lr: 0.00010666665912140161, took: 126.98s (avg: 126.98s), ETA: 0d:17h:13m:12s [TRAIN] loss: 0.4066, iou: 0.4296, f1: 0.5934 [EVAL] loss: 0.3807, iou: 0.4541, f1: 0.6193
