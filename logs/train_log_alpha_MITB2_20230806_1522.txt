

** [alpha] Launch Training on 20230806_1522
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": true,
  "architecture": "SEGFORMER",
  "baseModel": "MITB2",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 500,
  "resume": false,
  "prevEPOCH": 172,
  "resumeWeight": "./model_weights/ResNet50/20230605_1912_DLV3PP_ResNet50_BEST_AUG/variables/variables",
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 10,
  "early_stop": false,
  "patience": 50,
  "lr_scheduling": "wcos",
  "stepwise_scheduling": true,
  "lr": 0.0001,
  "optimizer": "AdamW",
  "decay_steps": 1.0,
  "warmup": 30,
  "train_annotation": "./Annotations/consolidate_train_db_20230711_1637.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230711_1637.txt",
  "exp_comment": "* Updated Annotations are used\n* Updated consolidate DB used (0711_1637 version) - Updated DB \n* This consolidate DB is updated from 0703_2119 version \n* 4 GPUs are used to train models\n* SEGFORMER Model W/ MIT B2 Pretrained Wegiths\n* Optimize perf: AdamW is used. w/ lr=0.001\n",
  "numGPUs": 4,
  "isCompleted": false,
  "config": "Config/TRAIN_SEGFORMER_NEWDB_20230711_lr.yaml",
  "numTrainDB": 11530,
  "numEvalDB": 3524
}
@20230806_1527 @20230806_1527 [EP 1/500] lr: 3.3333330975438002e-06, took: 263.79s (avg: 263.79s), ETA: 1d:12h:27m:17s [TRAIN] loss: 0.9908, iou: 0.0047, f1: 0.0092 [EVAL] loss: 0.9835, iou: 0.0083, f1: 0.0165
@20230806_1529 @20230806_1529 [EP 2/500] lr: 6.6666661950876005e-06, took: 137.09s (avg: 137.09s), ETA: 0d:18h:57m:6s [TRAIN] loss: 0.9594, iou: 0.0211, f1: 0.0405 [EVAL] loss: 0.9429, iou: 0.0296, f1: 0.0571
@20230806_1531 @20230806_1531 [EP 3/500] lr: 9.999999747378752e-06, took: 136.36s (avg: 136.36s), ETA: 0d:18h:46m:32s [TRAIN] loss: 0.8753, iou: 0.0678, f1: 0.1247 [EVAL] loss: 0.9066, iou: 0.0493, f1: 0.0934
@20230806_1534 @20230806_1534 [EP 4/500] lr: 1.3333332390175201e-05, took: 136.99s (avg: 136.99s), ETA: 0d:18h:44m:16s [TRAIN] loss: 0.8073, iou: 0.1092, f1: 0.1927 [EVAL] loss: 0.7577, iou: 0.1396, f1: 0.2423
@20230806_1536 @20230806_1536 [EP 5/500] lr: 1.666666503297165e-05, took: 137.39s (avg: 137.39s), ETA: 0d:18h:50m:15s [TRAIN] loss: 0.7432, iou: 0.1508, f1: 0.2568 [EVAL] loss: 0.7295, iou: 0.1583, f1: 0.2705
@20230806_1538 @20230806_1538 [EP 6/500] lr: 1.9999999494757503e-05, took: 136.03s (avg: 136.03s), ETA: 0d:18h:39m:44s [TRAIN] loss: 0.6879, iou: 0.1895, f1: 0.3121 [EVAL] loss: 0.6392, iou: 0.2227, f1: 0.3608
