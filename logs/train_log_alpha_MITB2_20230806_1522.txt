

** [alpha] Launch Training on 20230806_1522
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": true,
  "architecture": "SEGFORMER",
  "baseModel": "MITB2",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 500,
  "resume": false,
  "prevEPOCH": 172,
  "resumeWeight": "./model_weights/ResNet50/20230605_1912_DLV3PP_ResNet50_BEST_AUG/variables/variables",
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 10,
  "early_stop": false,
  "patience": 50,
  "lr_scheduling": "wcos",
  "stepwise_scheduling": true,
  "lr": 0.0001,
  "optimizer": "AdamW",
  "decay_steps": 1.0,
  "warmup": 30,
  "train_annotation": "./Annotations/consolidate_train_db_20230711_1637.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230711_1637.txt",
  "exp_comment": "* Updated Annotations are used\n* Updated consolidate DB used (0711_1637 version) - Updated DB \n* This consolidate DB is updated from 0703_2119 version \n* 4 GPUs are used to train models\n* SEGFORMER Model W/ MIT B2 Pretrained Wegiths\n* Optimize perf: AdamW is used. w/ lr=0.001\n",
  "numGPUs": 4,
  "isCompleted": false,
  "config": "Config/TRAIN_SEGFORMER_NEWDB_20230711_lr.yaml",
  "numTrainDB": 11530,
  "numEvalDB": 3524
}
@20230806_1527 @20230806_1527 [EP 1/500] lr: 3.3333330975438002e-06, took: 263.79s (avg: 263.79s), ETA: 1d:12h:27m:17s [TRAIN] loss: 0.9908, iou: 0.0047, f1: 0.0092 [EVAL] loss: 0.9835, iou: 0.0083, f1: 0.0165
@20230806_1529 @20230806_1529 [EP 2/500] lr: 6.6666661950876005e-06, took: 137.09s (avg: 137.09s), ETA: 0d:18h:57m:6s [TRAIN] loss: 0.9594, iou: 0.0211, f1: 0.0405 [EVAL] loss: 0.9429, iou: 0.0296, f1: 0.0571
@20230806_1531 @20230806_1531 [EP 3/500] lr: 9.999999747378752e-06, took: 136.36s (avg: 136.36s), ETA: 0d:18h:46m:32s [TRAIN] loss: 0.8753, iou: 0.0678, f1: 0.1247 [EVAL] loss: 0.9066, iou: 0.0493, f1: 0.0934
@20230806_1534 @20230806_1534 [EP 4/500] lr: 1.3333332390175201e-05, took: 136.99s (avg: 136.99s), ETA: 0d:18h:44m:16s [TRAIN] loss: 0.8073, iou: 0.1092, f1: 0.1927 [EVAL] loss: 0.7577, iou: 0.1396, f1: 0.2423
@20230806_1536 @20230806_1536 [EP 5/500] lr: 1.666666503297165e-05, took: 137.39s (avg: 137.39s), ETA: 0d:18h:50m:15s [TRAIN] loss: 0.7432, iou: 0.1508, f1: 0.2568 [EVAL] loss: 0.7295, iou: 0.1583, f1: 0.2705
@20230806_1538 @20230806_1538 [EP 6/500] lr: 1.9999999494757503e-05, took: 136.03s (avg: 136.03s), ETA: 0d:18h:39m:44s [TRAIN] loss: 0.6879, iou: 0.1895, f1: 0.3121 [EVAL] loss: 0.6392, iou: 0.2227, f1: 0.3608
@20230806_1541 @20230806_1541 [EP 7/500] lr: 2.3333332137553953e-05, took: 136.69s (avg: 136.69s), ETA: 0d:18h:37m:28s [TRAIN] loss: 0.6302, iou: 0.2321, f1: 0.3698 [EVAL] loss: 0.5736, iou: 0.2743, f1: 0.4264
@20230806_1543 @20230806_1543 [EP 8/500] lr: 2.6666664780350402e-05, took: 135.36s (avg: 135.36s), ETA: 0d:18h:27m:0s [TRAIN] loss: 0.5764, iou: 0.2743, f1: 0.4236 [EVAL] loss: 0.5178, iou: 0.3223, f1: 0.4822
@20230806_1545 @20230806_1545 [EP 9/500] lr: 2.999999742314685e-05, took: 136.02s (avg: 136.02s), ETA: 0d:18h:32m:56s [TRAIN] loss: 0.5297, iou: 0.3137, f1: 0.4703 [EVAL] loss: 0.4777, iou: 0.3585, f1: 0.5223
@20230806_1547 @20230806_1547 [EP 10/500] lr: 3.33333300659433e-05, took: 125.38s (avg: 125.38s), ETA: 0d:17h:0m:50s [TRAIN] loss: 0.4858, iou: 0.3520, f1: 0.5142 [EVAL] loss: 0.4334, iou: 0.3996, f1: 0.5666
@20230806_1549 @20230806_1549 [EP 11/500] lr: 3.6666664527729154e-05, took: 118.10s (avg: 118.10s), ETA: 0d:16h:1m:42s [TRAIN] loss: 0.4471, iou: 0.3882, f1: 0.5529 [EVAL] loss: 0.4057, iou: 0.4268, f1: 0.5943
@20230806_1551 @20230806_1551 [EP 12/500] lr: 3.9999998989515007e-05, took: 118.28s (avg: 118.28s), ETA: 0d:15h:59m:44s [TRAIN] loss: 0.4165, iou: 0.4180, f1: 0.5835 [EVAL] loss: 0.3879, iou: 0.4455, f1: 0.6121
@20230806_1553 @20230806_1553 [EP 13/500] lr: 4.333332981332205e-05, took: 118.18s (avg: 118.18s), ETA: 0d:15h:57m:46s [TRAIN] loss: 0.3869, iou: 0.4480, f1: 0.6131 [EVAL] loss: 0.3545, iou: 0.4804, f1: 0.6455
@20230806_1555 @20230806_1555 [EP 14/500] lr: 4.6666664275107905e-05, took: 118.41s (avg: 118.41s), ETA: 0d:15h:55m:48s [TRAIN] loss: 0.3592, iou: 0.4774, f1: 0.6408 [EVAL] loss: 0.3372, iou: 0.5001, f1: 0.6628
@20230806_1557 @20230806_1557 [EP 15/500] lr: 4.999999509891495e-05, took: 127.32s (avg: 127.32s), ETA: 0d:17h:6m:35s [TRAIN] loss: 0.3381, iou: 0.5005, f1: 0.6619 [EVAL] loss: 0.3170, iou: 0.5227, f1: 0.6830
@20230806_1600 @20230806_1600 [EP 16/500] lr: 5.3333329560700804e-05, took: 135.67s (avg: 135.67s), ETA: 0d:18h:9m:0s [TRAIN] loss: 0.3232, iou: 0.5171, f1: 0.6768 [EVAL] loss: 0.2972, iou: 0.5458, f1: 0.7028
@20230806_1602 @20230806_1602 [EP 17/500] lr: 5.666666402248666e-05, took: 135.61s (avg: 135.61s), ETA: 0d:18h:6m:45s [TRAIN] loss: 0.3122, iou: 0.5299, f1: 0.6878 [EVAL] loss: 0.2930, iou: 0.5507, f1: 0.7070
