

** [alpha] Launch Training on 20230813_1706 HPO desc: alpha_0.5_lambda_weight_0.33
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": false,
  "architecture": "DLV3+",
  "baseModel": "ResNet50",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 250,
  "resume": false,
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 14,
  "optimizer": "Adam",
  "loss": "combined_loss",
  "early_stop": false,
  "lr_scheduling": "exp",
  "lr": 0.0001,
  "stepwise_scheduling": true,
  "decay_steps": 1.0,
  "hpo_params": [
    "alpha",
    "lambda_weight"
  ],
  "lambda_weight": [
    0.1,
    0.2,
    0.33
  ],
  "alpha": [
    0.25,
    0.5,
    0.75
  ],
  "train_annotation": "./Annotations/consolidate_train_db_20230808_1942.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230808_1942.txt",
  "exp_comment": "* HPO test\n*   20230811: \n*   20230812: init lr -> 0.0001\n",
  "numGPUs": 4,
  "finalEPOCH": 250,
  "isCompleted": false,
  "config": "Config/TRAIN_DLV3_ResNet50_HPO.yaml",
  "numTrainDB": 11830,
  "numEvalDB": 3600,
  "numTrainSteps": 211,
  "numEvalSteps": 64,
  "train": {
    "loss": [],
    "iou": [],
    "f1": []
  },
  "eval": {
    "loss": [],
    "iou": [],
    "f1": []
  },
  "dbg_file_logging": "dbg_file_logging",
  "log_file": "<_io.TextIOWrapper name='logs/hpo_history_log/20230812_1837/hpo_log_DLV3+_ResNet50_alpha_0.5_lambda_weight_0.33.txt' mode='w' encoding='UTF-8'>",
  "github_logging": "github_logging",
  "github_log_file": "logs/hpo/DLV3+_ResNet50_alpha_0.5_lambda_weight_0.2.txt"
}
@20230813_1708 @20230813_1708 [EP 1/250] lr: 9.97904353425838e-05, took: 112.08s (avg: 112.08s), ETA: 0d:7h:44m:48s [TRAIN] loss: 13161.1533, iou: 0.0047, f1: 0.0093 [EVAL] loss: 13255.5391, iou: 0.0029, f1: 0.0058
@20230813_1709 @20230813_1709 [EP 2/250] lr: 9.958076407201588e-05, took: 61.39s (avg: 61.39s), ETA: 0d:4h:12m:8s [TRAIN] loss: 3097.3108, iou: 0.0332, f1: 0.0620 [EVAL] loss: 5014.8511, iou: 0.0038, f1: 0.0076
@20230813_1711 @20230813_1711 [EP 3/250] lr: 9.937196591636166e-05, took: 61.50s (avg: 61.50s), ETA: 0d:4h:11m:7s [TRAIN] loss: 1762.2963, iou: 0.0804, f1: 0.1451 [EVAL] loss: 3047.0159, iou: 0.0285, f1: 0.0550
@20230813_1712 @20230813_1712 [EP 4/250] lr: 9.916404087562114e-05, took: 61.55s (avg: 61.55s), ETA: 0d:4h:10m:6s [TRAIN] loss: 1282.9880, iou: 0.1134, f1: 0.1989 [EVAL] loss: 2315.2034, iou: 0.0482, f1: 0.0898
@20230813_1713 @20230813_1713 [EP 5/250] lr: 9.895698894979432e-05, took: 61.49s (avg: 61.49s), ETA: 0d:4h:9m:5s [TRAIN] loss: 1080.7440, iou: 0.1376, f1: 0.2363 [EVAL] loss: 2185.4470, iou: 0.0752, f1: 0.1376
@20230813_1714 @20230813_1714 [EP 6/250] lr: 9.875079558696598e-05, took: 61.63s (avg: 61.63s), ETA: 0d:4h:8m:4s [TRAIN] loss: 924.6799, iou: 0.1630, f1: 0.2741 [EVAL] loss: 2054.7087, iou: 0.0757, f1: 0.1377
@20230813_1716 @20230813_1716 [EP 7/250] lr: 9.854546806309372e-05, took: 61.62s (avg: 61.62s), ETA: 0d:4h:7m:3s [TRAIN] loss: 808.5389, iou: 0.1886, f1: 0.3107 [EVAL] loss: 1465.8878, iou: 0.1278, f1: 0.2228
@20230813_1717 @20230813_1717 [EP 8/250] lr: 9.834098455030471e-05, took: 61.47s (avg: 61.47s), ETA: 0d:4h:6m:2s [TRAIN] loss: 738.2432, iou: 0.2100, f1: 0.3401 [EVAL] loss: 1576.4502, iou: 0.1264, f1: 0.2208
@20230813_1718 @20230813_1718 [EP 9/250] lr: 9.813734504859895e-05, took: 61.55s (avg: 61.55s), ETA: 0d:4h:5m:1s [TRAIN] loss: 689.9995, iou: 0.2306, f1: 0.3678 [EVAL] loss: 1804.9299, iou: 0.1186, f1: 0.2084
@20230813_1719 @20230813_1719 [EP 10/250] lr: 9.793455683393404e-05, took: 61.61s (avg: 61.61s), ETA: 0d:4h:4m:0s [TRAIN] loss: 682.1587, iou: 0.2471, f1: 0.3894 [EVAL] loss: 2113.9521, iou: 0.0870, f1: 0.1561
@20230813_1720 @20230813_1720 [EP 11/250] lr: 9.773259807843715e-05, took: 61.61s (avg: 61.61s), ETA: 0d:4h:2m:59s [TRAIN] loss: 621.0674, iou: 0.2668, f1: 0.4142 [EVAL] loss: 1958.0276, iou: 0.1109, f1: 0.1953
@20230813_1721 @20230813_1721 [EP 12/250] lr: 9.753146878210828e-05, took: 61.57s (avg: 61.57s), ETA: 0d:4h:1m:58s [TRAIN] loss: 596.6673, iou: 0.2839, f1: 0.4353 [EVAL] loss: 2336.2920, iou: 0.0973, f1: 0.1714
@20230813_1722 @20230813_1722 [EP 13/250] lr: 9.733116894494742e-05, took: 61.58s (avg: 61.58s), ETA: 0d:4h:0m:57s [TRAIN] loss: 591.7551, iou: 0.2973, f1: 0.4514 [EVAL] loss: 1589.8820, iou: 0.1641, f1: 0.2774
