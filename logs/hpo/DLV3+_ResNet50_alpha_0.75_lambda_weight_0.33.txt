

** [alpha] Launch Training on 20230814_0635 HPO desc: alpha_0.75_lambda_weight_0.33
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": false,
  "architecture": "DLV3+",
  "baseModel": "ResNet50",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 250,
  "resume": false,
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 14,
  "optimizer": "Adam",
  "loss": "combined_loss",
  "early_stop": false,
  "lr_scheduling": "exp",
  "lr": 0.0001,
  "stepwise_scheduling": true,
  "decay_steps": 1.0,
  "hpo_params": [
    "alpha",
    "lambda_weight"
  ],
  "lambda_weight": [
    0.1,
    0.2,
    0.33
  ],
  "alpha": [
    0.25,
    0.5,
    0.75
  ],
  "train_annotation": "./Annotations/consolidate_train_db_20230808_1942.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230808_1942.txt",
  "exp_comment": "* HPO test\n*   20230811: \n*   20230812: init lr -> 0.0001\n",
  "numGPUs": 4,
  "finalEPOCH": 250,
  "isCompleted": false,
  "config": "Config/TRAIN_DLV3_ResNet50_HPO.yaml",
  "numTrainDB": 11830,
  "numEvalDB": 3600,
  "numTrainSteps": 211,
  "numEvalSteps": 64,
  "train": {
    "loss": [],
    "iou": [],
    "f1": []
  },
  "eval": {
    "loss": [],
    "iou": [],
    "f1": []
  },
  "dbg_file_logging": "dbg_file_logging",
  "log_file": "<_io.TextIOWrapper name='logs/hpo_history_log/20230812_1837/hpo_log_DLV3+_ResNet50_alpha_0.75_lambda_weight_0.33.txt' mode='w' encoding='UTF-8'>",
  "github_logging": "github_logging",
  "github_log_file": "logs/hpo/DLV3+_ResNet50_alpha_0.75_lambda_weight_0.2.txt"
}
@20230814_0637 @20230814_0637 [EP 1/250] lr: 9.97904353425838e-05, took: 113.06s (avg: 113.06s), ETA: 0d:7h:48m:57s [TRAIN] loss: 17028.6895, iou: 0.0037, f1: 0.0073 [EVAL] loss: 20807.4961, iou: 0.0029, f1: 0.0058
@20230814_0638 @20230814_0638 [EP 2/250] lr: 9.958076407201588e-05, took: 61.68s (avg: 61.68s), ETA: 0d:4h:12m:8s [TRAIN] loss: 3785.8142, iou: 0.0178, f1: 0.0337 [EVAL] loss: 6679.0400, iou: 0.0044, f1: 0.0087
@20230814_0640 @20230814_0640 [EP 3/250] lr: 9.937196591636166e-05, took: 61.76s (avg: 61.76s), ETA: 0d:4h:11m:7s [TRAIN] loss: 2172.5522, iou: 0.0626, f1: 0.1147 [EVAL] loss: 7271.0015, iou: 0.0132, f1: 0.0259
@20230814_0641 @20230814_0641 [EP 4/250] lr: 9.916404087562114e-05, took: 61.93s (avg: 61.93s), ETA: 0d:4h:10m:6s [TRAIN] loss: 1530.2850, iou: 0.0949, f1: 0.1690 [EVAL] loss: 2673.0181, iou: 0.0439, f1: 0.0827
@20230814_0642 @20230814_0642 [EP 5/250] lr: 9.895698894979432e-05, took: 61.87s (avg: 61.87s), ETA: 0d:4h:9m:5s [TRAIN] loss: 1210.8883, iou: 0.1224, f1: 0.2127 [EVAL] loss: 1862.0739, iou: 0.0815, f1: 0.1480
@20230814_0644 @20230814_0644 [EP 6/250] lr: 9.875079558696598e-05, took: 61.96s (avg: 61.96s), ETA: 0d:4h:8m:4s [TRAIN] loss: 1020.3032, iou: 0.1472, f1: 0.2504 [EVAL] loss: 1721.9817, iou: 0.1017, f1: 0.1831
@20230814_0645 @20230814_0645 [EP 7/250] lr: 9.854546806309372e-05, took: 61.86s (avg: 61.86s), ETA: 0d:4h:7m:3s [TRAIN] loss: 919.3636, iou: 0.1674, f1: 0.2802 [EVAL] loss: 1934.6688, iou: 0.0979, f1: 0.1766
@20230814_0646 @20230814_0646 [EP 8/250] lr: 9.834098455030471e-05, took: 61.79s (avg: 61.79s), ETA: 0d:4h:6m:2s [TRAIN] loss: 837.5965, iou: 0.1876, f1: 0.3089 [EVAL] loss: 2097.6633, iou: 0.1124, f1: 0.2000
