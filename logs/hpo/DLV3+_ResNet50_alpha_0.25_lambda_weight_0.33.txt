

** [alpha] Launch Training on 20230813_0338 HPO desc: alpha_0.25_lambda_weight_0.33
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": false,
  "architecture": "DLV3+",
  "baseModel": "ResNet50",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 250,
  "resume": false,
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 14,
  "optimizer": "Adam",
  "loss": "combined_loss",
  "early_stop": false,
  "lr_scheduling": "exp",
  "lr": 0.0001,
  "stepwise_scheduling": true,
  "decay_steps": 1.0,
  "hpo_params": [
    "alpha",
    "lambda_weight"
  ],
  "lambda_weight": [
    0.1,
    0.2,
    0.33
  ],
  "alpha": [
    0.25,
    0.5,
    0.75
  ],
  "train_annotation": "./Annotations/consolidate_train_db_20230808_1942.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230808_1942.txt",
  "exp_comment": "* HPO test\n*   20230811: \n*   20230812: init lr -> 0.0001\n",
  "numGPUs": 4,
  "finalEPOCH": 250,
  "isCompleted": false,
  "config": "Config/TRAIN_DLV3_ResNet50_HPO.yaml",
  "numTrainDB": 11830,
  "numEvalDB": 3600,
  "numTrainSteps": 211,
  "numEvalSteps": 64,
  "train": {
    "loss": [],
    "iou": [],
    "f1": []
  },
  "eval": {
    "loss": [],
    "iou": [],
    "f1": []
  },
  "dbg_file_logging": "dbg_file_logging",
  "log_file": "<_io.TextIOWrapper name='logs/hpo_history_log/20230812_1837/hpo_log_DLV3+_ResNet50_alpha_0.25_lambda_weight_0.33.txt' mode='w' encoding='UTF-8'>",
  "github_logging": "github_logging",
  "github_log_file": "logs/hpo/DLV3+_ResNet50_alpha_0.25_lambda_weight_0.2.txt"
}
@20230813_0340 @20230813_0340 [EP 1/250] lr: 9.97904353425838e-05, took: 108.79s (avg: 108.79s), ETA: 0d:7h:28m:12s [TRAIN] loss: 18897.4863, iou: 0.0035, f1: 0.0070 [EVAL] loss: 12427.9199, iou: 0.0028, f1: 0.0056
@20230813_0341 @20230813_0341 [EP 2/250] lr: 9.958076407201588e-05, took: 61.64s (avg: 61.64s), ETA: 0d:4h:12m:8s [TRAIN] loss: 4314.6406, iou: 0.0113, f1: 0.0217 [EVAL] loss: 5295.6069, iou: 0.0025, f1: 0.0051
@20230813_0343 @20230813_0343 [EP 3/250] lr: 9.937196591636166e-05, took: 61.44s (avg: 61.44s), ETA: 0d:4h:11m:7s [TRAIN] loss: 2537.2400, iou: 0.0489, f1: 0.0909 [EVAL] loss: 4613.5562, iou: 0.0161, f1: 0.0315
@20230813_0344 @20230813_0344 [EP 4/250] lr: 9.916404087562114e-05, took: 61.51s (avg: 61.51s), ETA: 0d:4h:10m:6s [TRAIN] loss: 1547.5779, iou: 0.0908, f1: 0.1625 [EVAL] loss: 2954.1030, iou: 0.0367, f1: 0.0694
@20230813_0345 @20230813_0345 [EP 5/250] lr: 9.895698894979432e-05, took: 61.50s (avg: 61.50s), ETA: 0d:4h:9m:5s [TRAIN] loss: 1179.2812, iou: 0.1221, f1: 0.2124 [EVAL] loss: 2556.5291, iou: 0.0540, f1: 0.1004
