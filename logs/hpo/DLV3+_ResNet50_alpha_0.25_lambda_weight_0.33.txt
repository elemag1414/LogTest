

** [alpha] Launch Training on 20230813_0338 HPO desc: alpha_0.25_lambda_weight_0.33
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": false,
  "architecture": "DLV3+",
  "baseModel": "ResNet50",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 250,
  "resume": false,
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 14,
  "optimizer": "Adam",
  "loss": "combined_loss",
  "early_stop": false,
  "lr_scheduling": "exp",
  "lr": 0.0001,
  "stepwise_scheduling": true,
  "decay_steps": 1.0,
  "hpo_params": [
    "alpha",
    "lambda_weight"
  ],
  "lambda_weight": [
    0.1,
    0.2,
    0.33
  ],
  "alpha": [
    0.25,
    0.5,
    0.75
  ],
  "train_annotation": "./Annotations/consolidate_train_db_20230808_1942.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230808_1942.txt",
  "exp_comment": "* HPO test\n*   20230811: \n*   20230812: init lr -> 0.0001\n",
  "numGPUs": 4,
  "finalEPOCH": 250,
  "isCompleted": false,
  "config": "Config/TRAIN_DLV3_ResNet50_HPO.yaml",
  "numTrainDB": 11830,
  "numEvalDB": 3600,
  "numTrainSteps": 211,
  "numEvalSteps": 64,
  "train": {
    "loss": [],
    "iou": [],
    "f1": []
  },
  "eval": {
    "loss": [],
    "iou": [],
    "f1": []
  },
  "dbg_file_logging": "dbg_file_logging",
  "log_file": "<_io.TextIOWrapper name='logs/hpo_history_log/20230812_1837/hpo_log_DLV3+_ResNet50_alpha_0.25_lambda_weight_0.33.txt' mode='w' encoding='UTF-8'>",
  "github_logging": "github_logging",
  "github_log_file": "logs/hpo/DLV3+_ResNet50_alpha_0.25_lambda_weight_0.2.txt"
}
@20230813_0340 @20230813_0340 [EP 1/250] lr: 9.97904353425838e-05, took: 108.79s (avg: 108.79s), ETA: 0d:7h:28m:12s [TRAIN] loss: 18897.4863, iou: 0.0035, f1: 0.0070 [EVAL] loss: 12427.9199, iou: 0.0028, f1: 0.0056
@20230813_0341 @20230813_0341 [EP 2/250] lr: 9.958076407201588e-05, took: 61.64s (avg: 61.64s), ETA: 0d:4h:12m:8s [TRAIN] loss: 4314.6406, iou: 0.0113, f1: 0.0217 [EVAL] loss: 5295.6069, iou: 0.0025, f1: 0.0051
@20230813_0343 @20230813_0343 [EP 3/250] lr: 9.937196591636166e-05, took: 61.44s (avg: 61.44s), ETA: 0d:4h:11m:7s [TRAIN] loss: 2537.2400, iou: 0.0489, f1: 0.0909 [EVAL] loss: 4613.5562, iou: 0.0161, f1: 0.0315
@20230813_0344 @20230813_0344 [EP 4/250] lr: 9.916404087562114e-05, took: 61.51s (avg: 61.51s), ETA: 0d:4h:10m:6s [TRAIN] loss: 1547.5779, iou: 0.0908, f1: 0.1625 [EVAL] loss: 2954.1030, iou: 0.0367, f1: 0.0694
@20230813_0345 @20230813_0345 [EP 5/250] lr: 9.895698894979432e-05, took: 61.50s (avg: 61.50s), ETA: 0d:4h:9m:5s [TRAIN] loss: 1179.2812, iou: 0.1221, f1: 0.2124 [EVAL] loss: 2556.5291, iou: 0.0540, f1: 0.1004
@20230813_0346 @20230813_0346 [EP 6/250] lr: 9.875079558696598e-05, took: 61.55s (avg: 61.55s), ETA: 0d:4h:8m:4s [TRAIN] loss: 984.6749, iou: 0.1461, f1: 0.2489 [EVAL] loss: 1689.8486, iou: 0.1037, f1: 0.1849
@20230813_0348 @20230813_0348 [EP 7/250] lr: 9.854546806309372e-05, took: 61.54s (avg: 61.54s), ETA: 0d:4h:7m:3s [TRAIN] loss: 908.8605, iou: 0.1622, f1: 0.2731 [EVAL] loss: 2311.3005, iou: 0.0625, f1: 0.1149
@20230813_0349 @20230813_0349 [EP 8/250] lr: 9.834098455030471e-05, took: 61.59s (avg: 61.59s), ETA: 0d:4h:6m:2s [TRAIN] loss: 803.8839, iou: 0.1910, f1: 0.3140 [EVAL] loss: 2318.8796, iou: 0.0782, f1: 0.1428
@20230813_0350 @20230813_0350 [EP 9/250] lr: 9.813734504859895e-05, took: 61.57s (avg: 61.57s), ETA: 0d:4h:5m:1s [TRAIN] loss: 747.9967, iou: 0.2065, f1: 0.3353 [EVAL] loss: 1619.6473, iou: 0.1326, f1: 0.2319
@20230813_0351 @20230813_0351 [EP 10/250] lr: 9.793455683393404e-05, took: 61.45s (avg: 61.45s), ETA: 0d:4h:4m:0s [TRAIN] loss: 676.6187, iou: 0.2267, f1: 0.3624 [EVAL] loss: 2136.7263, iou: 0.0900, f1: 0.1604
@20230813_0352 @20230813_0352 [EP 11/250] lr: 9.773259807843715e-05, took: 61.62s (avg: 61.62s), ETA: 0d:4h:2m:59s [TRAIN] loss: 670.8739, iou: 0.2298, f1: 0.3663 [EVAL] loss: 1907.9844, iou: 0.1234, f1: 0.2176
@20230813_0353 @20230813_0353 [EP 12/250] lr: 9.753146878210828e-05, took: 61.55s (avg: 61.55s), ETA: 0d:4h:1m:58s [TRAIN] loss: 652.1249, iou: 0.2509, f1: 0.3940 [EVAL] loss: 1755.9161, iou: 0.1363, f1: 0.2372
@20230813_0354 @20230813_0354 [EP 13/250] lr: 9.733116894494742e-05, took: 61.53s (avg: 61.53s), ETA: 0d:4h:0m:57s [TRAIN] loss: 602.5980, iou: 0.2720, f1: 0.4205 [EVAL] loss: 1923.8407, iou: 0.1341, f1: 0.2339
