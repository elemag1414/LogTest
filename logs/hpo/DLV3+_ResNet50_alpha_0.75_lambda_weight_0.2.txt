

** [alpha] Launch Training on 20230814_0205 HPO desc: alpha_0.75_lambda_weight_0.2
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": false,
  "architecture": "DLV3+",
  "baseModel": "ResNet50",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 250,
  "resume": false,
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 14,
  "optimizer": "Adam",
  "loss": "combined_loss",
  "early_stop": false,
  "lr_scheduling": "exp",
  "lr": 0.0001,
  "stepwise_scheduling": true,
  "decay_steps": 1.0,
  "hpo_params": [
    "alpha",
    "lambda_weight"
  ],
  "lambda_weight": [
    0.1,
    0.2,
    0.33
  ],
  "alpha": [
    0.25,
    0.5,
    0.75
  ],
  "train_annotation": "./Annotations/consolidate_train_db_20230808_1942.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230808_1942.txt",
  "exp_comment": "* HPO test\n*   20230811: \n*   20230812: init lr -> 0.0001\n",
  "numGPUs": 4,
  "finalEPOCH": 250,
  "isCompleted": false,
  "config": "Config/TRAIN_DLV3_ResNet50_HPO.yaml",
  "numTrainDB": 11830,
  "numEvalDB": 3600,
  "numTrainSteps": 211,
  "numEvalSteps": 64,
  "train": {
    "loss": [],
    "iou": [],
    "f1": []
  },
  "eval": {
    "loss": [],
    "iou": [],
    "f1": []
  },
  "dbg_file_logging": "dbg_file_logging",
  "log_file": "<_io.TextIOWrapper name='logs/hpo_history_log/20230812_1837/hpo_log_DLV3+_ResNet50_alpha_0.75_lambda_weight_0.2.txt' mode='w' encoding='UTF-8'>",
  "github_logging": "github_logging",
  "github_log_file": "logs/hpo/DLV3+_ResNet50_alpha_0.75_lambda_weight_0.1.txt"
}
@20230814_0207 @20230814_0207 [EP 1/250] lr: 9.97904353425838e-05, took: 113.83s (avg: 113.83s), ETA: 0d:7h:48m:57s [TRAIN] loss: 13482.6084, iou: 0.0052, f1: 0.0103 [EVAL] loss: 14620.3613, iou: 0.0029, f1: 0.0057
@20230814_0208 @20230814_0208 [EP 2/250] lr: 9.958076407201588e-05, took: 61.70s (avg: 61.70s), ETA: 0d:4h:12m:8s [TRAIN] loss: 3198.5105, iou: 0.0458, f1: 0.0850 [EVAL] loss: 6503.4185, iou: 0.0060, f1: 0.0119
@20230814_0210 @20230814_0210 [EP 3/250] lr: 9.937196591636166e-05, took: 61.78s (avg: 61.78s), ETA: 0d:4h:11m:7s [TRAIN] loss: 1868.4543, iou: 0.0953, f1: 0.1699 [EVAL] loss: 4028.8523, iou: 0.0279, f1: 0.0537
@20230814_0211 @20230814_0211 [EP 4/250] lr: 9.916404087562114e-05, took: 61.79s (avg: 61.79s), ETA: 0d:4h:10m:6s [TRAIN] loss: 1370.8394, iou: 0.1366, f1: 0.2349 [EVAL] loss: 2218.3462, iou: 0.0823, f1: 0.1494
