

** [alpha] Launch Training on 20230812_1837 HPO desc: alpha_0.25_lambda_weight_0.1
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "plot": false,
  "architecture": "DLV3+",
  "baseModel": "ResNet50",
  "gpuIDs": "0,1,2,3",
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 250,
  "resume": false,
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 14,
  "optimizer": "Adam",
  "loss": "combined_loss",
  "early_stop": false,
  "lr_scheduling": "exp",
  "lr": 0.0001,
  "stepwise_scheduling": true,
  "decay_steps": 1.0,
  "hpo_params": [
    "alpha",
    "lambda_weight"
  ],
  "lambda_weight": [
    0.1,
    0.2,
    0.33
  ],
  "alpha": [
    0.25,
    0.5,
    0.75
  ],
  "train_annotation": "./Annotations/consolidate_train_db_20230808_1942.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230808_1942.txt",
  "exp_comment": "* HPO test\n*   20230811: \n*   20230812: init lr -> 0.0001\n",
  "numGPUs": 4,
  "finalEPOCH": 0,
  "isCompleted": false,
  "config": "Config/TRAIN_DLV3_ResNet50_HPO.yaml",
  "numTrainDB": 11830,
  "numEvalDB": 3600,
  "numTrainSteps": 211,
  "numEvalSteps": 64,
  "train": {
    "loss": [],
    "iou": [],
    "f1": []
  },
  "eval": {
    "loss": [],
    "iou": [],
    "f1": []
  },
  "dbg_file_logging": "dbg_file_logging",
  "log_file": "<_io.TextIOWrapper name='logs/hpo_history_log/20230812_1837/hpo_log_DLV3+_ResNet50_alpha_0.25_lambda_weight_0.1.txt' mode='w' encoding='UTF-8'>"
}
@20230812_1839 @20230812_1839 [EP 1/250] lr: 9.97904353425838e-05, took: 114.48s (avg: 114.48s), ETA: 0d:7h:53m:6s [TRAIN] loss: 29851.8320, iou: 0.0087, f1: 0.0171 [EVAL] loss: 87540.9531, iou: 0.0026, f1: 0.0053
@20230812_1840 @20230812_1840 [EP 2/250] lr: 9.958076407201588e-05, took: 61.94s (avg: 61.94s), ETA: 0d:4h:12m:8s [TRAIN] loss: 4848.7334, iou: 0.0412, f1: 0.0777 [EVAL] loss: 9944.8076, iou: 0.0028, f1: 0.0056
@20230812_1841 @20230812_1841 [EP 3/250] lr: 9.937196591636166e-05, took: 61.58s (avg: 61.58s), ETA: 0d:4h:11m:7s [TRAIN] loss: 2656.0393, iou: 0.0712, f1: 0.1300 [EVAL] loss: 6860.9956, iou: 0.0032, f1: 0.0064
@20230812_1843 @20230812_1843 [EP 4/250] lr: 9.916404087562114e-05, took: 61.42s (avg: 61.42s), ETA: 0d:4h:10m:6s [TRAIN] loss: 1768.8489, iou: 0.0975, f1: 0.1735 [EVAL] loss: 5881.1533, iou: 0.0035, f1: 0.0069
@20230812_1844 @20230812_1844 [EP 5/250] lr: 9.895698894979432e-05, took: 61.57s (avg: 61.57s), ETA: 0d:4h:9m:5s [TRAIN] loss: 1344.2313, iou: 0.1189, f1: 0.2076 [EVAL] loss: 4437.8101, iou: 0.0148, f1: 0.0291
@20230812_1845 @20230812_1845 [EP 6/250] lr: 9.875079558696598e-05, took: 61.62s (avg: 61.62s), ETA: 0d:4h:8m:4s [TRAIN] loss: 1065.6831, iou: 0.1418, f1: 0.2426 [EVAL] loss: 3270.4155, iou: 0.0612, f1: 0.1148
@20230812_1846 @20230812_1846 [EP 7/250] lr: 9.854546806309372e-05, took: 61.37s (avg: 61.37s), ETA: 0d:4h:7m:3s [TRAIN] loss: 922.8101, iou: 0.1633, f1: 0.2742 [EVAL] loss: 2440.7964, iou: 0.0969, f1: 0.1757
