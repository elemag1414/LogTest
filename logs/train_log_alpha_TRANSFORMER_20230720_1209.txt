

** [alpha] Launch Training on 20230720_1209
{
  "HOST": "alpha",
  "SAVE": true,
  "github_log": true,
  "architecture": "UNETR",
  "baseModel": "TRANSFORMER",
  "numGPUs": 4,
  "modelSize": [
    512,
    512
  ],
  "initialWeight": [
    null,
    null
  ],
  "num_epochs": 500,
  "num_layers": 12,
  "hidden_dim": 768,
  "mlp_dim": 3072,
  "num_heads": 12,
  "dropout_rate": 0.1,
  "patch_size": 32,
  "num_channels": 3,
  "resume": false,
  "prevEPOCH": 172,
  "resumeWeight": "./model_weights/ResNet50/20230605_1912_DLV3PP_ResNet50_BEST_AUG/variables/variables",
  "augmentation": true,
  "temperature_shift": 15,
  "Flag": true,
  "p": 0.2,
  "acc_thresh": 0.5,
  "batch_size": 10,
  "lr_scheduling": "cos",
  "lr": 0.01,
  "decay_steps": 1.0,
  "train_annotation": "./Annotations/consolidate_train_db_20230711_1637.txt",
  "eval_annotation": "./Annotations/consolidate_eval_db_20230711_1637.txt",
  "exp_comment": "* Updated Annotations are used\n* Updated consolidate DB used (0711_1637 version) - Updated DB \n* This consolidate DB is updated from 0703_2119 version \n* 4 GPUs are used to train models\n",
  "isCompleted": false,
  "config": "Config/TRAIN_UNETR_NEWDB_20230711.yaml",
  "numTrainDB": 11530,
  "numEvalDB": 3524
}
@20230720_1215 @20230720_1215 [EP 1/500] lr: 0.009999999776482582, took: 354.41s (avg: 354.41s), ETA: 2d:1h:4m:6s [TRAIN] loss: 0.9849, iou: 0.0079, f1: 0.0151 [EVAL] loss: 0.9942, iou: 0.0029, f1: 0.0058
@20230720_1219 @20230720_1219 [EP 2/500] lr: 0.009999901056289673, took: 280.32s (avg: 280.32s), ETA: 1d:14h:44m:0s [TRAIN] loss: 0.9574, iou: 0.0225, f1: 0.0426 [EVAL] loss: 1.0000, iou: 0.0000, f1: 0.0000
@20230720_1224 @20230720_1224 [EP 3/500] lr: 0.009999604895710945, took: 280.75s (avg: 280.75s), ETA: 1d:14h:39m:20s [TRAIN] loss: 0.8868, iou: 0.0629, f1: 0.1132 [EVAL] loss: 0.9766, iou: 0.0124, f1: 0.0234
@20230720_1229 @20230720_1229 [EP 4/500] lr: 0.009999112226068974, took: 280.64s (avg: 280.64s), ETA: 1d:14h:34m:40s [TRAIN] loss: 0.8503, iou: 0.0852, f1: 0.1497 [EVAL] loss: 1.0000, iou: 0.0000, f1: 0.0000
@20230720_1233 @20230720_1233 [EP 5/500] lr: 0.009998421184718609, took: 280.63s (avg: 280.63s), ETA: 1d:14h:30m:0s [TRAIN] loss: 0.8063, iou: 0.1129, f1: 0.1937 [EVAL] loss: 0.9270, iou: 0.0398, f1: 0.0730
@20230720_1238 @20230720_1238 [EP 6/500] lr: 0.009997532702982426, took: 280.43s (avg: 280.43s), ETA: 1d:14h:25m:20s [TRAIN] loss: 0.7864, iou: 0.1259, f1: 0.2136 [EVAL] loss: 0.9779, iou: 0.0113, f1: 0.0221
@20230720_1243 @20230720_1243 [EP 7/500] lr: 0.009996447712182999, took: 280.61s (avg: 280.61s), ETA: 1d:14h:20m:40s [TRAIN] loss: 0.7790, iou: 0.1310, f1: 0.2210 [EVAL] loss: 1.0000, iou: 0.0000, f1: 0.0000
@20230720_1247 @20230720_1247 [EP 8/500] lr: 0.009995164349675179, took: 281.24s (avg: 281.24s), ETA: 1d:14h:24m:12s [TRAIN] loss: 0.7667, iou: 0.1397, f1: 0.2333 [EVAL] loss: 0.9725, iou: 0.0141, f1: 0.0275
@20230720_1252 @20230720_1252 [EP 9/500] lr: 0.009993684478104115, took: 280.55s (avg: 280.55s), ETA: 1d:14h:11m:20s [TRAIN] loss: 0.7597, iou: 0.1444, f1: 0.2403 [EVAL] loss: 0.9044, iou: 0.0516, f1: 0.0956
@20230720_1257 @20230720_1257 [EP 10/500] lr: 0.009992008097469807, took: 280.18s (avg: 280.18s), ETA: 1d:14h:6m:40s [TRAIN] loss: 0.7637, iou: 0.1419, f1: 0.2363 [EVAL] loss: 1.0000, iou: 0.0000, f1: 0.0000
@20230720_1302 @20230720_1302 [EP 11/500] lr: 0.009990133345127106, took: 280.34s (avg: 280.34s), ETA: 1d:14h:2m:0s [TRAIN] loss: 0.7645, iou: 0.1409, f1: 0.2355 [EVAL] loss: 0.9707, iou: 0.0149, f1: 0.0293
